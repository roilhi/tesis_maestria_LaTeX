Automatically generated by Mendeley Desktop 1.13.3
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Preferences -> BibTeX in Mendeley Desktop

@article{Makhoul1973,
abstract = {The autocorrelation method of linear prediction is formulated in the time, autocorrelation, and spectral domains. The analysis is shown to be that of approximating the short-time signal power spectrum by an all-pole spectrum. The method is compared with other methods of spectral analysis such as analysis-by-synthesis and cepstral smoothing. It is shown that this method can be regarded as another method of analysis-by-synthesis where a number of poles is specified, with the advantages of noniterative computation and an error measure which leads to a better spectral envelope fit for an all-pole spectrum. Compared to spectral analysis by cepstral smoothing in conjunction with the chirp z transform (CZT), this method is expected to give a better spectral envelope fit (for an all-pole spectrum) and to be less sensitive to the effects of high pitch on the spectrum. The normalized minimum error is defined and its possible usefulness as a voicing detector is discussed.},
author = {Makhoul, John},
journal = {Audio and Eletroacoustics, IEEE Transactions on},
keywords = {linear prediction,spectral analysis,speech analysis},
number = {3},
pages = {140--148},
title = {{Spectral Analysis of Speech by Linear Prediction}},
volume = {21},
year = {1973}
}
@article{Zhang1998a,
abstract = {A time-frequency scaling transformation based on the matching pursuit (MP) method is developed for the phonocardiogram (PCG). The MP method decomposes a signal into a series of time-frequency atoms by using an iterative process. The modification of the time scale of the PCG can be performed without perceptible change in its spectral characteristics. It is also possible to modify the frequency scale without changing the temporal properties. The technique has been tested on 11 PCG's containing heart sounds and different murmurs. A scaling/inverse-scaling procedure was used for quantitative evaluation of the scaling performance. Both the spectrogram and a MP-based Wigner distribution were used for visual comparison in the time-frequency domain. The results showed that the technique is suitable and effective for the time-frequency scale transformation of both the transient property of the heart sounds and the more complex random property of the murmurs. It is also shown that the effectiveness of the method is strongly related to the optimization of the parameters used for the decomposition of the signals.},
author = {Zhang, X and Durand, L G and Senhadji, L and Lee, H C and Coatrieux, J L},
doi = {10.1109/10.704866},
file = {:Users/roilhiibarra/Google Drive/tesis\_maestria\_roilhi/Bibliograf\'{\i}a/Art\'{\i}culos MP en PCG (1)/zhang98\_TF\_scaling\_PCGMP.pdf:pdf},
issn = {0018-9294},
journal = {IEEE transactions on bio-medical engineering},
keywords = {Cardiovascular,Computer-Assisted,Fourier Analysis,Heart Murmurs,Heart Murmurs: diagnosis,Heart Sounds,Humans,Models,Phonocardiography,Phonocardiography: methods,Sensitivity and Specificity,Signal Processing,Time Factors},
month = aug,
number = {8},
pages = {972--9},
pmid = {9691572},
title = {{Time-frequency scaling transformation of the phonocardiogram based of the matching pursuit method}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3515452\&tool=pmcentrez\&rendertype=abstract},
volume = {45},
year = {1998}
}
@article{Senhadji1995,
abstract = {The authors' study made use of wavelet transforms to describe and recognize isolated cardiac beats. The choice of the wavelet family as well as the selection of the analyzing function into these families are discussed. The criterion used in the first case was the correct classification rate, and in the second case, the correlation coefficient between the original pattern and the reconstructed one. Two types of description have been considered-the energy-based representation and the extrema distribution estimated at each decomposition level-and their quality has been assessed by using principal component analysis. Their capability of discrimination between normal, premature ventricular contraction, and ischemic beats has been studied by means of linear discriminant analysis. This work leads also, for the problem at hand, to the identification of the most relevant resolution levels},
author = {Senhadji, L. and Carrault, G. and Bellanger, J. J. and Passariello, G.},
doi = {10.1109/51.376755},
issn = {07395175},
journal = {IEEE Engineering in Medicine and Biology Magazine},
number = {2},
pages = {167--173},
title = {{Comparing wavelet transforms for recognizing cardiac patterns}},
volume = {14},
year = {1995}
}
@article{Dammann1972,
author = {Dammann, C. L. and McDaniel, L.D. and Maddox, C. L.},
journal = {Bell System Technical Journal},
number = {8},
pages = {1675--1699},
title = {{D2 channel bank: Multiplexing and coding}},
volume = {51},
year = {1972}
}
@inproceedings{Jasper2010,
author = {Jasper, Julian and Othman, Khair Razlan},
booktitle = {Electronics and Information Engineering (ICIEIE), 2010 International Conference On},
doi = {10.1109/ICEIE.2010.5559770},
file = {:Users/roilhiibarra/Google Drive/tesis\_maestria\_roilhi/Bibliograf\'{\i}a/articulos\_relacionados/jasper10\_phonocardiogram\_feature\_extraction.pdf:pdf},
isbn = {978-1-4244-7679-4},
keywords = {-biometrics,correct recognition,energy,envelogram,pcg,phonocardiogram,wavelet transform},
month = aug,
pages = {V2--228},
publisher = {IEEE},
title = {{Feature extraction for human identification based on envelogram signal analysis of cardiac sounds in time-frequency domain}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5559770},
volume = {2},
year = {2010}
}
@incollection{Gray2006,
abstract = {The fundamental theorems on the asymptotic behavior of eigenvalues, inverses, and products of banded Toeplitz matrices and Toeplitz matrices with absolutely summable elements are derived in a tutorial manner. Mathematical elegance and generality are sacrificed for conceptual simplicity and insight in the hope of making these results available to engineers lacking either the background or endurance to attack the mathematical literature on the subject. By limiting the generality of the matrices considered, the essential ideas and results can be conveyed in a more intuitive manner without the mathematical machinery required for the most general cases. As an application the results are applied to the study of the covariance matrices and their factors of linear models of discrete time random processes. The fundamental theorems on the asymptotic behavior of eigenvalues, inverses, and products of banded Toeplitz matrices and Toeplitz matrices with absolutely summable elements are derived in a tutorial manner. Mathematical elegance and generality are sacrificed for conceptual simplicity and insight in the hope of making these results available to engineers lacking either the background or endurance to attack the mathematical literature on the subject. By limiting the generality of the matrices considered, the essential ideas and results can be conveyed in a more intuitive manner without the mathematical machinery required for the most general cases. As an application the results are applied to the study of the covariance matrices and their factors of linear models of discrete time random processes.},
author = {Gray, Robert M.},
booktitle = {Foundations and Trends in Communications and Information Theory},
doi = {10.1561/0100000006},
isbn = {9781933019239},
issn = {1567-2190},
pages = {155--239},
publisher = {now publishers inc.},
title = {{Toeplitz and Circulant Matrices: A Review}},
volume = {2(3)},
year = {2006}
}
@article{Smith1999,
abstract = {Use of a bilinear conformal map to achieve a frequency warping nearly identical to that of the Bark frequency scale is described. Because the map takes the unit circle to itself, its form is that of the transfer function of a first-order allpass filter. Since it is a first-order map, it preserves the model order of rational systems, making it a valuable frequency warping technique for use in audio filter design. A closed-form weighted-equation-error method is derived that computes the optimal mapping coefficient as a function of sampling rate, and the solution is shown to be generally indistinguishable from the optimal least-squares solution. The optimal Chebyshev mapping is also found to be essentially identical to the optimal least-squares solution. The expression 0.8517[arctan(0.06583fs)]1/2-0.916 is shown to accurately approximate the optimal allpass coefficient as a function of sampling rate fs in kHz for sampling rates greater than 1 kHz. A filter design example is included that illustrates improvements due to carrying out the design over a Bark scale. Corresponding results are also given and compared for approximating the related \&ldquo;equivalent rectangular bandwidth (ERB) scale\&rdquo; of Moore and Glasberg (ACTA Acustica, vo.82, p.335-45, 1996) using a first-order allpass transformation. Due to the higher frequency resolution called for by the ERB scale, particularly at low frequencies, the first-order conformal map is less able to follow the desired mapping, and the error is two to three times greater than the Bark-scale case, depending on the sampling rate},
author = {Smith, Julius O. and Abel, Jonathan S.},
doi = {10.1109/89.799695},
issn = {10636676},
journal = {Speech and Audio Processing, IEEE Transactions on},
keywords = {Bark,Bilinear transform,ERB,Filter design,Frequency warping},
number = {6},
pages = {697--708},
pmid = {799695},
title = {{Bark and ERB Bilinear Transforms}},
volume = {7},
year = {1999}
}
@book{Rabiner1993,
abstract = {Provides a theoretically sound, technically accurate, and complete description of the basic knowledge and ideas that constitute a modern system for speech recognition by machine. Covers production, perception, and acoustic-phonetic characterization of the speech signal; signal processing and analysis methods for speech recognition; pattern comparison techniques; speech recognition system design and implementation; theory and implementation of hidden Markov models; speech recognition based on connected word models; large vocabulary continuous speech recognition; and task- oriented application of automatic speech recognition. For practicing engineers, scientists, linguists, and programmers interested in speech recognition.},
author = {Rabiner, LR Lawrence and Juang, Biing-Hwang BH},
booktitle = {Prentice Hall},
doi = {10.1002/ev.1647},
isbn = {0130151572},
pages = {507},
publisher = {Prentice Hall},
title = {{Fundamentals of Speech Recognition}},
url = {http://cmp.felk.cvut.cz/cmp/support/phd112.html},
volume = {103},
year = {1993}
}
@book{Papoulis1984,
address = {New York},
author = {Papoulis, A},
booktitle = {McGraw-Hill},
edition = {2nd},
publisher = {McGraw-Hill},
title = {{Probability, Random Variables, and Stochastic Processes}},
year = {1984}
}
@inproceedings{Krstulovic2006,
abstract = {Matching Pursuit (MP) aims at finding sparse decompositions of signals over redundant bases of elementary waveforms. Traditionally, MP has been considered too slow an algorithm to be applied to real-life problems with high-dimensional signals. Indeed, in terms of floating points operations, its typical numerical implementations have a complexity of O(N2) and are associated with impractical runtimes. In this paper, we propose a new architecture which exploits the structure shared by many redundant MP dictionaries, and thus decreases its complexity to O(N log N). This architecture is implemented in a new software toolkit, called MPTK (the Matching Pursuit Toolkit), which is able to reach, e.g., 0.25\&\#215;real time for a typical MP analysis scenario applied to a 1 hour long audio track. This substantial acceleration makes it possible, from now on, to explore and apply MP in the framework of real-life, high-dimensional data processing problems.},
author = {Gribonval, R. and Krstulovic, S.},
booktitle = {Acoustics Speech and Signal Processing, 2006. ICASSP 2006 Proceedings. 2006 IEEE International Conference on},
doi = {10.1109/ICASSP.2006.1660699},
isbn = {1-4244-0469-X},
issn = {1520-6149},
pages = {III--III},
publisher = {IEEE},
title = {{MPTK: Matching Pursuit Made Tractable}},
volume = {3},
year = {2006}
}
@article{Musmann2006,
abstract = {In 1988 the International Standardization Organization (ISO) established the Motion Picture Expert Group (MPEG) to develop a digital coding standard for video and audio signals in order to enable interactive video and audio signals on digital storage media. The MPEG Audio Group started with members from 14 research institutions in order to develop a digital audio coding standard guided by a chairman. As a result the MPEG-1, Layer I, Layer II and Layer III coding standards have been developed and proposed for coding of stereo audio signals at 2 times 192 kbit/s, 2 times 128 kbit/s and 2 times 64 kbit/s in 1992. Later, the abbreviation "mp3" or "MP3" was introduced in order to substitute the long name of the successful MPEG-1, Layer III coding standard. This paper describes the development of the MP3 coding standard and its essential components as contributed by the members of the MPEG Audio Group},
author = {Musmann, Hans Georg},
doi = {10.1109/TCE.2006.1706505},
issn = {00983063},
journal = {IEEE Transactions on Consumer Electronics},
keywords = {Audio coding,MP3,MPEG standards},
number = {3},
pages = {1043--1049},
title = {{Genesis of the MP3 audio coding standard}},
volume = {52},
year = {2006}
}
@article{Ghofrani1993,
abstract = {Time-frequency distributions have been used extensively for nonstationary signal analysis, they describe how the frequency content of a signal is changing in time. The Wigner-Ville distribution (WVD) is the best known. The draw back of WVD is cross-term artifacts. An alternative to the WVD is Gabor transform (GT), a signal decomposition method, which displays the time-frequency energy of a signal on a joint t-f plane without generating considerable cross-terms. In this paper the WVD and GT of ultrasound echo signals are computed analytically.},
author = {Ghofrani, S and Ayatollahi, A and Shamsollahi, M B},
issn = {00678856},
journal = {Biomedical sciences instrumentation},
pages = {142--147},
pmid = {12724883},
title = {{Wigner–Ville Distribution and Gabor transform in Doppler ultrasound signal processing}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/20160789},
volume = {39},
year = {2002}
}
@article{Sava1998,
abstract = {The paper evaluates the performance of an automatic adaptive time-frequency method to detect each cardiac cycle of a phonocardiogram (PCG) and extract average heart sounds and PCG cycles. The proposed method combines a global search of the PCG, in terms of the energy distribution of the most important components, with a local search relating to the specific events found within a cardiac cycle. The method is applied to 100 PCG recordings from 50 patients with an aortic bioprosthetic valve. The performance of the proposed method is compared with a commonly used semi-automatic method that is based on the combined analysis of an electrocardiogram (ECG) and the PCG signal. Results show that the proposed method clearly outperforms the semi-automatic method, especially in the case of patients with malfunctioning bioprostheses. By eliminating the need to record an ECG as the time-reference signal, this method reduces hardware overheads when analysis of PCG signals is the primary aim. It is also independent of subjective human judgment for selection of reference templates and threshold levels. Furthermore, the method is robust to artefacts, background noise and other kinds of signal interferences. With minor modifications, the procedure described could be applied to other types of biomedical signal in order to extract coherent transient components and identify specific events.},
author = {Sava, H and Pibarot, P and Durand, L G},
file = {:Users/roilhiibarra/Google Drive/tesis\_maestria\_roilhi/Bibliograf\'{\i}a/sava98\_application\_mp\_pcg.pdf:pdf},
issn = {0140-0118},
journal = {Medical and Biological Engineering and Computing},
keywords = {Aortic Valve,Computer-Assisted,Heart Auscultation,Heart Valve Prosthesis,Humans,Phonocardiography,Prosthesis Failure,Signal Processing},
month = may,
number = {3},
pages = {302--308},
pmid = {9747569},
title = {{Application of the matching pursuit method for structural decomposition and averaging of phonocardiographic signals}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/9747569},
volume = {36},
year = {1998}
}
@article{Mano1995,
abstract = {This paper describes the design of a speech coder called pitch synchronous innovation CELP (PSI-CELP) for low hit-rate mobile communications. PSI-CELP is based on CELP, but has more adaptive excitation structures. In voiced frames, instead of conventional random excitation vectors, PSI-CELP converts even the random excitation vectors to have pitch periodicity by repeating stored random vectors as well as by using an adaptive codebook, in silent, unvoiced, and transient frames, the coder stops using the adaptive codebook and switches to fixed random codebooks. The PSI-CELP coder also implements novel structures and techniques: an FIR-type perceptual weighting filter using unquantized LPC parameters, a random codebook with a conjugate structure trained to be robust against channel errors, codebook search with delayed decision, a gain quantization with sloped amplitude, and a moving average prediction coding of LSP parameters, Our speech coder is implemented by DSP chips. Its coded speech quality at 3.6 kb/s with 2.0 kb/s redundancy is comparable to that of the Japanese full-rate VSELP coder at 6.7 kb/s with 4.5 kb/s redundancy. The basic structure of this PSI-CELP coder has been chosen as the Japanese half-rate speech codec for digital cellular telecommunications},
author = {Mano, Kazunori and Moriya, Takehiro and Miki, Satoshi and Ohmuro, Hitoshi and Ikeda, Kazunaga and Ikedo, Iotaro},
doi = {10.1109/49.363148},
issn = {07338716},
journal = {Selected Areas in Communications, IEEE Journal on},
number = {1},
pages = {31--41},
title = {{Design of a pitch synchronous innovation CELP coder for mobile communications}},
volume = {13},
year = {1995}
}
@inproceedings{Gerson1990,
abstract = {The vector sum excited linear prediction speech coder is presented. It utilizes a codebook with a structure that allows for a very efficient search procedure. Other advantages of the VSELP codebook structure are discussed, and a detailed description of an 8-kb/s VSELP coder is given. This coder was selected by the Telecommunications Industry Association (TIA) as the standard for use in North American digital cellular telephone systems. The coder uses two VSELP excitation codebooks, a gain quantizer which is robust to channel errors, and a novel adaptive pre/postfilter arrangement},
author = {Gerson, I.A. and Jasiuk, M.A.},
booktitle = {Acoustics, Speech, and Signal Processing, 1990. ICASSP-90., 1990 International Conference on},
doi = {10.1109/ICASSP.1990.115749},
issn = {1520-6149},
pages = {461--464},
publisher = {IEEE},
title = {{Vector sum excited linear prediction (VSELP) speech coding at 8 kbps}},
year = {1990}
}
@book{Gersho1992,
abstract = {This book is devoted to the theory and practice of signal compression; i.e. data compression applied to signals such as speech, audio, images and video signals. The emphasis is on the conversion of analog waveforms into efficient digital representations and on the compression of digital information into the fewest possible bits. Both operations should yield the highest possible reconstruction fidelity subject to constraints on the bit rate and implementation complexity. The conversion of signals into such efficient digital representations has several goals: to minimize the communication capacity required for transmission of high quality signals such as speech and images or, equivalently, to obtain the best possible fidelity over an available communication channel; to minimize the storage capacity required for saving such information in fast storage media and in archival data bases or, equivalently, to obtain the best possible quality for the largest amount of information stored in a given medium; to provide the simplest possible accurate descriptions of a signal so as to minimize the subsequent complexity of signal processing algorithms such as classification, transformation and encryption. In addition to these common goals of communication, storage, and signal processing systems, efficient coding of both analog and digital information is intimately connected to a variety of other fields such as pattern recognition, image classification, speech recognition, cluster analysis regression, and decision tree design. Thus techniques from each field can often be extended to another and combined signal processing operations can take advantage of the similar algorithm structures and designs. This book has been written for use in a graduate course on quantization and signal compression and represents the most comprehensive reference available for research scientists and practitioners working in fields related to the topic.},
author = {Gersho, Allen and Gray, Robert M.},
booktitle = {Kluwer Academic Press},
doi = {10.1007/978-1-4615-3626-0\_10},
isbn = {0792391810},
publisher = {Springer},
title = {{Vector Quantization and Signal Compression}},
url = {http://www.amazon.com/dp/0792391810},
volume = {159},
year = {1992}
}
@inproceedings{Alajarin2005,
author = {Alajar\'{\i}n, J Mart\'{\i}nez and Merino, R Ruiz},
booktitle = {Actas del XXIII Congreso Anual de la Sociedad Espa\~{n}ola de Ingenier\'{\i}a Biom\'{e}dica (CASEIB 2005)},
file = {:Users/roilhiibarra/Google Drive/tesis\_maestria\_roilhi/Bibliograf\'{\i}a/articulos\_relacionados/alajarin05\_CompresionPCG\_basadaEventos.pdf:pdf},
pages = {423--426},
publisher = {Fundaci\'{o}n Rogelio Segovia para el Desarrollo de las Telecomunicaciones},
title = {{Compresi\'{o}n de fonocardiogramas basada en eventos}},
year = {2005}
}
@inproceedings{Alajarin2004,
author = {Alajar\'{\i}n, Juan Mart\'{\i}nez and Merino, Ram\'{o}n Ruiz},
booktitle = {Actas del XXII Congreso Anual de la Sociedad Espa\~{n}ola de Ingenier\'{\i}a Biom\'{e}dica (CASEIB 2004)},
file = {:Users/roilhiibarra/Google Drive/tesis\_maestria\_roilhi/Modelado\_PCG/martinez04\_PCG\_WPT.pdf:pdf},
pages = {181--184},
title = {{Compresi\'{o}n de fonocardiogramas mediante las transformadas wavelet y wavelet packet}},
year = {2004}
}
@article{Bosi1997,
author = {Bosi, Marina and Brandenburg, Karlheinz and Quackenbush, Schuyler and Fielder, Louis and Akagiri, Kenzo and Fuchs, Hendrik and Dietz, Martin},
journal = {Journal of the Audio Engineering Society},
number = {10},
pages = {789--814},
title = {{ISO/IEC MPEG-2 advanced audio coding}},
volume = {45},
year = {1997}
}
@inproceedings{Edler2000,
abstract = {For very low bit rate audio coding applications in mobile communications or on the Internet, parametric audio coding has evolved as a technique complementing the more traditional approaches. These are transform codecs originally designed for achieving CD-like quality on one hand, and specialized speech codecs on the other hand. Both of these techniques usually represent the audio signal waveform in a way such that the decoder output signal gives an approximation of the encoder input signal, while taking into account perceptual criteria. Compared to this approach, in parametric audio coding the models of the signal source and of human perception are extended. The source model is now based on the assumption that the audio signal is the sum of \&amp;ldquo;components,\&amp;rdquo; each of which can be approximated by a relatively simple signal model with a small number of parameters. The perception model is based on the assumption that the sound of the decoder output signal should be as similar as possible to that of the encoder input signal. Therefore, the approximation of waveforms is no longer necessary. This approach can lead to a very efficient representation. However, a suitable set of models for signal components, a good decomposition, and a good parameter estimation are all vital for achieving maximum audio quality. We give an overview on the current status of parametric audio coding developments and demonstrate advantages and challenges of this approach. Finally, we indicate possible directions of further improvements},
author = {Edler, B. and Purnhagen, H.},
booktitle = {Signal Processing Proceedings, 2000. WCC 2000-ICSP 2000. 2000. 5th International Conference on},
doi = {10.1109/ICOSP.2000.894435},
isbn = {0-7803-5747-7},
pages = {21--24},
title = {{Parametric audio coding}},
volume = {1},
year = {2000}
}
@inproceedings{Nieblas2013,
abstract = {The segmentation of heart sound signals is the first step of analysis for many applications such as computer-aided auscultation, heart sound classification or signal compression. In this paper we present a novel heart sound segmentation technique based on the Matching Pursuit algorithm. We also show that Gabor atoms can provide highly effective representation of audio signals. The performance of the proposed method has been evaluated using a dataset composed of 151 sound attacks comprising several cardiac pathologies. The reported algorithm showed high performance, achieving a detection rate of 97.5\% and 96\% for heart sound onsets and offsets respectively. © 2013 IEEE.},
author = {Nieblas, Carlos I. and Alonso, Miguel A. and Conte, Roberto and Villarreal, Salvador},
booktitle = {Digital Signal Processing and Signal Processing Education Meeting (DSP/SPE), 2013 IEEE},
doi = {10.1109/DSP-SPE.2013.6642572},
editor = {IEEE},
isbn = {978-1-4799-1616-0},
pages = {96--100},
title = {{High performance heart sound segmentation algorithm based on Matching Pursuit}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84890677424\&partnerID=tZOtx3y1},
year = {2013}
}
@misc{series2014,
author = {Series, BS},
pages = {1--33},
publisher = {International Telecommunication Union},
title = {{Method for subjective assessment of intermediate quality level of audio systems}},
url = {http://www.itu.int/dms\_pubrec/itu-r/rec/bs/R-REC-BS.1534-2-201406-I!!PDF-E.pdf},
year = {2014}
}
@article{Chen1997,
abstract = {The authors propose a simulated first heart sound (S1) signal that can be used as a reference signal to evaluate the accuracy of time-frequency representation techniques for studying multicomponent signals. The composition of this simulated S1 is based on the hypothesis that an S1 recorded on the thorax over the apical area of the heart is composed of constant frequency vibrations from the mitral valve and a frequency modulated vibration from the myocardium. Essentially, the simulated S1 consists of a valvular component and a myocardial component. The valvular component is modelled as two exponentially decaying sinusoids of 50 Hz and 150 Hz and the myocardial component is modelled by a frequency modulated wave between 20 Hz and 100 Hz. The study shows that the simulated S1 has temporal and spectral characteristics similar to S1 recorded in humans and dogs. It also shows that the spectrogram cannot resolve the three components of the simulated S1. It is concluded that it is necessary to search for a better time-frequency representation technique for studying the time-frequency distribution of multicomponent signals such as the simulated S1.},
author = {Chen, D and Durand, L.G. and Lee, HC},
issn = {0140-0118},
journal = {Medical and Biological Engineering and Computing},
keywords = {Animals,Cardiovascular,Computer Simulation,Computer-Assisted,Dogs,Heart,Heart Sounds,Heart Valve Prosthesis,Heart: physiology,Humans,Mitral Valve,Mitral Valve: physiology,Models,Phonocardiography,Signal Processing},
number = {4},
pages = {306--310},
pmid = {9327603},
title = {{Time-frequency analysis of the first heart sound. Part 1: Simulation and analysis}},
url = {http://www.springerlink.com/index/274T112357885202.pdf},
volume = {35},
year = {1997}
}
@inproceedings{Hedayioglu2012,
abstract = {We propose a denoising and segmentation technique for the second heart sound (S2). To denoise, Matching Pursuit (MP) was applied using a set of non-linear chirp signals as atoms. We show that the proposed method can be used to segment the phonocardiogram of the second heart sound into its two clinically meaningful components: the aortic (A2) and pulmonary (P2) components.},
author = {Hedayioglu, F. and Jafari, M. G. and Mattos, S. S. and Plumbley, M. D. and Coimbra, M. T.},
booktitle = {Engineering in International Conference of Medicine and Biology Society, San Diego, CA, USA},
doi = {10.1109/EMBC.2012.6346705},
isbn = {9781424441198},
issn = {1557170X},
pages = {3440--3443},
pmid = {23366666},
title = {{Denoising and segmentation of the second heart sound using matching pursuit}},
year = {2012}
}
@article{Makhoul1975,
abstract = {Thii paper gives an exposition of linear prediction in the analysis of discrete signals. The signal is modeled as a linear combination of its past values and present and past values of a hypothetical input to a system whose output is the given signal. In the frequency domain, this is equivalent to modeling the signal spectrum by a pole-zero spectrum. The major part of the paper is devoted to all-pole models. The model parameters are obtained by a least squares analysis in the time domain. Two methods result, depending on whether the signal is assumed to be stationary or nonstationary. The same results are then derived in the frequency domain. The resulting spectral matching formulation allows for the modeling of selected portions of a spectnun, for arbitrary spectral shaping in the frequency domain, and for the modeling of continuous as well as discrete spectra. This also leads to a discussion of the advantages and disadvantages of the least squares error criterion. A spectral interpretation is given to the normalized minimum prediction error. Applications of the normalized error are given, including the determination of an “optimal” number of poles, The use of linear prediction in data compression is reviewed. For purposes of transmission, particular attention is given to the quantization and encoding of the reflection (or partial correlation) coefficients. Finally, a brief introduction to pole-zero modeling is given.},
author = {Makhoul, John},
doi = {10.1109/PROC.1975.9792},
issn = {00189219},
journal = {Proceedings of the IEEE},
number = {4},
pages = {561--580},
title = {{Linear prediction. A tutorial review}},
volume = {63},
year = {1975}
}
@article{Schroeder1979,
abstract = {In any speech coding system that adds noise to the speech signal, the primary goal should be to reduce the noise power as mcuh as possible, but to make the noise inaudible or to minimize its subjective loudness. "Hiding" the noise under the signal spectrum is feasible because of human auditory masking: sounds whose spectrum falls near the masking threshold of another sound are either completely masked by tho other sound or reduced in loudness. In speech coding applications, the "other sound" is, of course, the speech signal itself. In this paper we report new results of masking and loudness reduction of noise and describe the design principles of speech coding systems exploiting auditory masking.},
author = {Schroeder, Manfred R. and Atal, Bishnu S. and Hall, J.L.},
doi = {10.1121/1.383662},
isbn = {1216470650},
issn = {00014966},
journal = {The Journal of the Acoustical Society of America},
number = {6},
pages = {1647--1652},
title = {{Optimizing digital speech coders by exploiting masking properties of the human ear}},
volume = {66},
year = {1979}
}
@inproceedings{Kipper1991,
abstract = {Code-excited-linear-predictive (CELP) coding has led to speech coding schemes with a good speech quality at 8 kb/s and a fair quality at data rates of about 4.8 kb/s. In the present work, the authors propose a novel method for improving the speech quality of a CELP codec at low bit rates by adaptation of the excitation codebook (ACELP). The adaptive cookbook consists of a set of basic excitation vectors which are adapted to an analysis speech frame by calculating optimum amplitude values. The amplitudes are quantized and encoded at a very low bit rate using a gain shape vector quantizer. The results of simulation experiments show that the mean squared error by CELP with an adaptive codebook is substantially lower than that of CELP with a fixed stochastic codebook. In informal listening tests the quality of the speech processed by the adaptive CELP scheme was superior and less speaker-dependent compared to a conventional CELP scheme},
author = {Kipper, U. and Reininger, H. and Wolf, D.},
booktitle = {Signals, Systems \& Computers. 1991. Conference Record of the Twenty-Fifth Asilomar Conference on},
doi = {10.1109/ACSSC.1991.186585},
editor = {IEEE},
isbn = {0-8186-2470-1},
issn = {1058-6393},
pages = {940--943},
title = {{CELP coding with adaptive excitation codebooks}},
year = {1991}
}
@article{Mallat1993,
abstract = {The authors introduce an algorithm, called matching pursuit, that decomposes any signal into a linear expansion of waveforms that are selected from a redundant dictionary of functions. These waveforms are chosen in order to best match the signal structures. Matching pursuits are general procedures to compute adaptive signal representations. With a dictionary of Gabor functions a matching pursuit defines an adaptive time-frequency transform. They derive a signal energy distribution in the time-frequency plane, which does not include interference terms, unlike Wigner and Cohen class distributions. A matching pursuit isolates the signal structures that are coherent with respect to a given dictionary. An application to pattern extraction from noisy signals is described. They compare a matching pursuit decomposition with a signal expansion over an optimized wavepacket orthonormal basis, selected with the algorithm of Coifman and Wickerhauser see (IEEE Trans. Informat. Theory, vol. 38, Mar. 1992)},
author = {Mallat, Stephane G. and Zhang, Zhifeng},
doi = {10.1109/78.258082},
isbn = {1053-587X},
issn = {1053587X},
journal = {IEEE Transactions on Signal Processing},
number = {12},
pages = {3397--3415},
pmid = {22094447},
title = {{Matching pursuits with time-frequency dictionaries}},
volume = {41},
year = {1993}
}
@inproceedings{Soong1984a,
abstract = {Line Spectrum Pair (LSP) was first introduced by Itakura [1,2] as an alternative LPC spectral representations. It was found that this new representation has such interesting properties as (1) all zeros of LSP polynomials are on the unit circle, (2) the corresponding zeros of the symmetric and anti-symmetric LSP polynomials are interlaced, and (3) the reconstructed LPC all-pole filter preserves its minimum phase property if (1) and (2) are kept intact through a quantization procedure. In this paper we prove all these properties via a "phase function." The statistical characteristics of LSP frequencies are investigated by analyzing a speech data base. In addition, we derive an expression for spectral sensitivity with respect to single LSP frequency deviation such that some insight on their quantization effects can be obtained. Results on multi-pulse LPC using LSP for spectral information compression are finally presented.},
author = {Soong, F. and Juang, B.},
booktitle = {Acoustics, Speech, and Signal Processing, IEEE International Conference on ICASSP'84.},
doi = {10.1109/ICASSP.1984.1172448},
issn = {07367791},
pages = {37--40},
publisher = {IEEE},
title = {{Line spectrum pair (LSP) and speech data compression}},
volume = {9},
year = {1984}
}
@inproceedings{Miki1994,
abstract = {This paper proposes high-quality and low bit-rate (3.6 and 2.4 kbit/s) coders using a pitch synchronous innovation CELP (PSI-CELP) method or a phase adaptive PSI-CELP. PSI-CELP, which is used as the excitation structure of the half-rate codec for the standard of Japanese digital mobile telephony, is based on CELP but adds pitch synchronous innovation, which means that even random codevectors are adaptively converted to have pitch periodicity for voiced frames. Phase adaptive PSI-CELP makes not only the periodicity, like in PSI-CELP, but also the phase of random codevectors equal to those of an adaptive codevector. The subjective qualities of the 3.6- and 2.4-kbit/s coders exceed those of the 6.7-kbit/S VSELP coder, which is the full-rate codec for the standard of Japanese digital mobile telephony, and-the 4.8-kbit/s U.S. Federal Standard 1016 CELP coder, respectively, in the error-free condition},
author = {Miki, S. and Mano, K. and Moriya, Y. and Oguchi, K. and Ohmuro, H.},
booktitle = {Acoustics, Speech and Signal Processing 1994. ICASSP-94., 1994 IEEE International Conference on},
doi = {10.1109/ICASSP.1994.389705},
isbn = {0-7803-1775-0},
issn = {1520-6149},
pages = {II--113},
publisher = {IEEE},
title = {{A pitch synchronous innovation CELP (PSI-CELP) coder for 2-4 kbit/s}},
volume = {ii},
year = {1994}
}
@article{Makhoul1975c,
abstract = {Linear prediction (LP) is presented as a spectral modeling technique in which the signal spectrum is modeled by an all-pole spectrum. The method allows for arbitrary spectral shaping in the frequency domain, and for modeling of continuous as well as discrete spectra (such as filter bank spectra). In addition, using the method of selective linear, prediction, all-pole modeling is applied to selected portions of the spectrum, with applications to speech recognition and speech compression. LP is compared with traditional analysis-by-synthesis (AbS) techniques for spectral modeling. It is found that linear prediction offers computational advantages over AbS, as well as better modeling properties if the variations of the signal spectrum from the desired spectral model are large. For relatively smooth spectra and for filter bank spectra, AbS is judged to give better results. Finally, a sub-optimal solution to the problem of all-zero modeling using LP is given.},
author = {Makhoul, J.},
doi = {10.1109/TASSP.1975.1162685},
issn = {0096-3518},
journal = {Acoustics, Speech, and Signal Processing, IEEE Transactions on},
number = {3},
pages = {283--296},
title = {{Spectral linear prediction: Properties and applications}},
volume = {23},
year = {1975}
}
@article{RuizReyes2010,
author = {{Ruiz Reyes}, N. and Candeas, P.V.},
doi = {10.1109/TASL.2009.2037396},
file = {:Users/roilhiibarra/Google Drive/tesis\_maestria\_roilhi/Bibliograf\'{\i}a/ruiz2010\_parametric\_audio\_coding.pdf:pdf},
issn = {1558-7916},
journal = {IEEE Transactions on Audio, Speech, and Language Processing},
month = mar,
number = {3},
pages = {447--460},
title = {{Adaptive Signal Modeling Based on Sparse Approximations for Scalable Parametric Audio Coding}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5352322},
volume = {18},
year = {2010}
}
@inproceedings{Mahnke2009,
abstract = {Heart disease is a major cause of worldwide morbidity and mortality. Properly performed, the cardiac auscultatory examination (listening to the heart with a stethoscope) is an inexpensive, widely available tool in the detection and management of heart disease. Unfortunately, accurate interpretation of heartsounds by primary care providers is fraught with error, leading to missed diagnosis of disease and/or excessive costs associated with evaluation of normal variants. Therefore, automated heartsound analysis, also known as computer aided auscultation (CAA), has the potential to become a cost-effective screening and diagnostic tool in the primary care setting. A cardiologist's suggestions for CAA system design and algorithmic development are provided.},
author = {Mahnke, C Becket},
booktitle = {Engineering in Medicine and Biology Society, 2009. EMBC 2009. Annual International Conference of the IEEE},
doi = {10.1109/IEMBS.2009.5332551},
file = {:Users/roilhiibarra/Google Drive/tesis\_maestria\_roilhi/Bibliograf\'{\i}a/articulos\_relacionados/mahnke09\_heartsound\_cargiologist\_perspective.pdf:pdf},
issn = {1557-170X},
keywords = {Acoustics,Algorithms,Automation,Cardiology,Cardiology: instrumentation,Cardiology: methods,Computer-Assisted,Computer-Assisted: methods,Diagnosis,Equipment Design,Heart Auscultation,Heart Diseases,Heart Diseases: pathology,Humans,Phonocardiography,Phonocardiography: instrumentation,Phonocardiography: methods,Reproducibility of Results,Signal Processing,Software,Stethoscopes,User-Computer Interface},
month = jan,
pages = {3115--3118},
pmid = {19963568},
publisher = {IEEE},
title = {{Automated heartsound analysis/computer-aided auscultation: a cardiologist's perspective and suggestions for future development}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19963568},
year = {2009}
}
@book{Mallat1999,
abstract = {Fourier presented a memoir to the Institut de France in 1807 where he claimed that any periodic function can be represented as a series of harmonically related sinusoids. This idea had a profound impact in mathematical analysis, physics and engineering, but it took one and a half centuries to understand the convergence of Fourier series and complete the theory of Fourier integrals. Fourier was motivated by the study of heat diffusion, which is governed by a linear differential equation. However, the Fourier transform diagonalizes all linear time-invariant operators, which are the building blocks of signal processing. It is, therefore, not only the starting point of our exploration but the basis of all further developments. Two -dimensional Fourier Transform is a straightforward extension of the one-dimensional Fourier transform. The two-dimensional case is briefly reviewed for image processing applications.},
author = {Mallat, St\'{e}phane},
booktitle = {A Wavelet Tour of Signal Processing},
doi = {10.1016/B978-012466606-1/50004-0},
isbn = {9780124666061},
issn = {10538801},
publisher = {Academic Press},
title = {{A Wavelet Tour of Signal Processing}},
url = {http://www.sciencedirect.com/science/article/pii/B9780124666061500040},
year = {1999}
}
@book{Rabiner1978,
author = {Rabiner, L. and Schafer, R. and Ronald, W.},
publisher = {Prentice Hall},
title = {{Digital processing of speech signals}},
year = {1978}
}
@inproceedings{Itakura1968,
author = {Itakura, F. and Saito, S.},
booktitle = {Proceedings of the 6th International Congress in Acoustics},
pages = {C17--C20},
title = {{Analysis syntesis telephony based on the maximum likelihood method}},
year = {1968}
}
@article{Viswanathan1975,
abstract = {Several alternate sets of parameters that represent the linear predictor are investigated as transmission parameters for linear predictive speech compression systems. Although each of these sets provides equivalent information about the linear predictor, their properties under quantization are different. The results of a comparative study of the various parameter sets are reported. Specifically it is concluded that the reflection coefficients are the best set for use as transmission parameters. A more detailed investigation of the reflection coefficients is then carried out using a spectral sensitivity measure. A method of optimally quantizing the reflection coefficients is derived using a minimax spectral error criterion and the sensitivity analysis. The method consists of transforming the reflection coefficients to the so-called log area ratios and linearly quantizing them. A qualitative study on changes in pole locations due to quantization serves to corroborate the use of this optimal quantization. An optimal bit allocation strategy for the transmission parameters is also presented. The use of another spectral sensitivity measure renders logarithms of the ratios of normalized errors associated with linear predictors of successive orders as the optimal quantization parameters. Informal listening tests indicate that the use of log area ratios for quantization leads to better synthesis than the use of log error ratios.},
author = {Viswanathan, R. and Makhoul, J.},
doi = {10.1109/TASSP.1975.1162675},
issn = {0096-3518},
journal = {Acoustics, Speech and Signal Processing, IEEE Transactions on},
number = {3},
pages = {309--321},
title = {{Quantization properties of transmission parameters in linear predictive systems}},
volume = {23},
year = {1975}
}
@article{Itakura1975,
author = {Itakura, F.},
journal = {The Journal of the Acoustical Society of America},
number = {S1},
pages = {S35--S35},
title = {{Line spectrum representation of linear predictor coefficients of speech signals}},
volume = {57},
year = {1975}
}
@article{Messer2001,
author = {Messer, Sheila R and Agzarian, John and Abbott, Derek},
doi = {10.1016/S0026-2692(01)00095-7},
file = {:Users/roilhiibarra/Google Drive/tesis\_maestria\_roilhi/Bibliograf\'{\i}a/articulos\_relacionados/messer01\_phonocardiogram\_denoising.pdf:pdf},
issn = {00262692},
journal = {Microelectronics Journal},
keywords = {denoising,heart sound analysis,heartbeat analysis,hilbert transform,phonocardiogram,wavelets},
month = dec,
number = {12},
pages = {931--941},
title = {{Optimal wavelet denoising for phonocardiograms}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0026269201000957},
volume = {32},
year = {2001}
}
@inproceedings{Choi1996,
abstract = {A new vector sum excited linear prediction (VSELP) speech coder employing mutually orthonormal regular pulse vectors is presented. Since the algorithm uses an efficient vector-sum codebook consisting of mutually orthonormal regular pulse basis vectors, computational load for codebook search can be significantly reduced, while the reconstructed speech quality is equivalent to that of the conventional VSELP. The method, referred to as regular pulse VSELP (RP-VSELP), employs the Gram-Schmidt (GS) procedure to orthonormalize the basis vectors designed in a form of regular pulses. To enhance the SNR performance, the basis vectors are optimized using an iterative closed-loop training process},
author = {Choi, Yong Soo and Kang, Hong Goo and Youn, Dae Hee},
booktitle = {Acoustics, Speech, and signal Processing, 1996. ICASSP-96. Conference Proceedings., 1996 IEEE International Conference on},
doi = {10.1109/ICASSP.1996.541156},
isbn = {0-7803-3192-3},
issn = {1520-6149},
pages = {554--557},
publisher = {IEEE},
title = {{A fast VSELP speech coder based on mutually orthonormal regular pulse vectors}},
volume = {1},
year = {1996}
}
@book{Bosi2003,
author = {Bosi, Marina and Goldberg, Richard E.},
file = {:Users/roilhiibarra/Google Drive/tesis\_maestria\_roilhi/Intro\_to\_digital\_audio\_coding.pdf:pdf},
publisher = {Springer},
title = {{Introduction to digital audio coding and standards}},
url = {http://books.google.com.mx/books?hl=es\&lr=\&id=oHWIRmHpi8YC\&oi=fnd\&pg=PR13\&dq=itroduction+to+digital+audio+coding+and+standards\&ots=rtDsVJ--vB\&sig=Gk0\_-pcvLXSZQVBfyk23qZ7M42U\&redir\_esc=y\#v=onepage\&q=itroduction to digital audio coding and standards\&f=false},
year = {2003}
}
@article{Valin2010a,
abstract = {With increasing quality requirements for multimedia communications, audio codecs must maintain both high quality and low delay. Typically, audio codecs offer either low delay or high quality, but rarely both. We propose a codec that simultaneously addresses both these requirements, with a delay of only 8.7 ms at 44.1 kHz. It uses gain-shape algebraic vector quantization in the frequency domain with time-domain pitch prediction. We demonstrate that the proposed codec operating at 48 kb/s and 64 kb/s out-performs both G.722.1C and MP3 and has quality comparable to AAC-LD, despite having less than one fourth of the algorithmic delay of these codecs.},
author = {Valin, Jean Marc and Terriberry, Timothy B. and Montgomery, Christopher and Maxwell, Gregory},
doi = {10.1109/TASL.2009.2023186},
issn = {15587916},
journal = {Audio, Speech and Language Processing, IEEE Transactions on},
keywords = {Audio coding,Low-delay,Speech coding,Super-wideband,Transform coding},
number = {1},
pages = {58--67},
title = {{A high-quality speech and audio codec with less than 10-ms delay}},
volume = {18},
year = {2010}
}
@article{Watrous2008,
abstract = {BACKGROUND: As many as 50-70\% of asymptomatic children referred for specialist evaluation or echocardiography because of a murmur have no heart disease. HYPOTHESIS: Computer-assisted auscultation (CAA) can improve the sensitivity and specificity of referrals for evaluation of heart murmurs. METHODS: Seven board-certified primary care physicians were evaluated both without and with use of a computer-based decision-support system using 100 prerecorded patient heart sounds (55 innocent murmurs, 30 pathological murmurs, 15 without murmur). The sensitivity and specificity of their murmur referral decisions relative to American College of Cardiology/American Heart Association (ACC/AHA) guidelines, and sensitivity and specificity of murmur detection and characterization (innocent versus pathological) were measured. RESULTS: Sensitivity for detection of murmurs significantly increased with use of CAA from 76.6 to 89.1\% (p <0.001), while specificity remained unaffected (80.0 versus 81.0\%). Computer-assisted auscultation improved sensitivity of correctly identifying pathological murmur cases from 82.4 to 90.0\%, and specificity of correctly identifying benign cases (with innocent or no murmurs) from 74.9 to 88.8\%. (p <0.001). Referral sensitivity increased from 86.7 to 92.9\%, while specificity increased from 63.5 to 78.6\% using CAA (p <0.001). CONCLUSIONS: Computer-assisted auscultation appears to be a promising new technology for informing the referral decisions of primary care physicians.},
author = {Watrous, Raymond L and Thompson, W Reid and Ackerman, Stacey J},
doi = {10.1002/clc.20185},
file = {:Users/roilhiibarra/Google Drive/tesis\_maestria\_roilhi/Bibliograf\'{\i}a/articulos\_relacionados/watrous08\_computer\_auscultation.pdf:pdf},
issn = {0160-9289},
journal = {Clinical cardiology},
keywords = {Clinical,Computer-Assisted,Continuity of Patient Care,Decision Support Systems,Diagnosis,Health Status Indicators,Heart Auscultation,Heart Auscultation: instrumentation,Heart Murmurs,Heart Murmurs: diagnosis,Heart Murmurs: physiopathology,Heart Murmurs: ultrasonography,Hemodynamics,Humans,Image Processing,Referral and Consultation,Sensitivity and Specificity},
month = feb,
number = {2},
pages = {79--83},
pmid = {18257026},
title = {{The impact of computer-assisted auscultation on physician referrals of asymptomatic patients with heart murmurs}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/18257026},
volume = {31},
year = {2008}
}
@article{Debbal2008,
abstract = {This paper is concerned with a synthesis study of the fast Fourier transform (FFT), the short-time Fourier transform (STFT), the Wigner distribution (WD) and the wavelet transform (WT) in analysing the phonocardiogram signal (PCG). It is shown that these transforms provide enough features of the PCG signals that will help clinics to obtain qualitative and quantitative measurements of the time-frequency (TF) PCG signal characteristics and consequently aid diagnosis. Similarly, it is shown that the frequency content of such a signal can be determined by the FFT without difficulties. The studied techniques (FT, STFT, WD, CWT, DWT and PWT) of analysis can thus be regarded as complementary in the TF analysis of the PCG signal; each will relate to a part distinct from the analysis in question. ?? 2007 Elsevier Ltd. All rights reserved.},
author = {Debbal, S. M. and Bereksi-Reguig, F.},
doi = {10.1016/j.compbiomed.2007.09.006},
issn = {00104825},
journal = {Computers in Biology and Medicine},
keywords = {FFT,Phonocardiogram,STFT,Signal analysis,Signal processing,Sounds,Time-frequency analysis,WD,WT},
number = {2},
pages = {263--280},
pmid = {18037395},
title = {{Computerized heart sounds analysis}},
volume = {38},
year = {2008}
}
@article{Blanco-Velasco2005,
abstract = {The quality measurement of the reconstructed signal in an electrocardiogram (ECG) compression scheme must be obtained by objective means being the percentage root-mean-square difference (PRD) the most widely used. However, this parameter is dependent on the dc level so that confusion can be stated in the evaluation of ECG compressors. In this communication, it will be shown that if the performance of an ECG coder is evaluated only in terms of quality, considering exclusively the PRD parameter, incorrect conclusions can be inferred. The objective of this work is to propose the joint use of several parameters, as simulations will show, effectiveness and performance of the ECG coder are evaluated with more precision, and the way of inferring conclusions from the obtained results is more reliable. © 2005 IPEM. Published by Elsevier Ltd. All rights reserved.},
author = {Blanco-Velasco, Manuel and Cruz-Rold\'{a}n, Fernando and Godino-Llorente, J. Ignacio and Blanco-Velasco, Joaqu\'{\i}n and Armiens-Aparicio, Carlos and L\'{o}pez-Ferreras, Francisco},
doi = {10.1016/j.medengphy.2005.02.007},
isbn = {1350-4533},
issn = {13504533},
journal = {Medical Engineering and Physics},
keywords = {Electrocardiogram (ECG),Filter bank,Wavelet packets (WP)},
number = {9},
pages = {798--802},
pmid = {15869896},
title = {{On the use of PRD and CR parameters for ECG compression}},
volume = {27},
year = {2005}
}
@misc{LitmannBase,
author = {Litmann},
title = {{Ruidos cardiacos y pulmonares}},
url = {http://solutions.3m.com.mx/wps/portal/3M/es\_MX/3M-Littmann-LA/home/Education/SoundLibrary/},
year = {2013}
}
@mastersthesis{castorena2012,
abstract = {Una de las prioridades de cualquier sociedad debe ser la de proveer servicios de salud adecuados para la poblaci ́on. Dentro del per ́ımetro de un ́area urbana, no existe gran problema para recibir atenci ́on m ́edica ba ́sica basada en auscultacio ́n con estetos- copio, el cual es la herramienta de diagn ́ostico ma ́s utilizada por los m ́edicos generales. Sin embargo, en muchas localidades de nuestro pa ́ıs no se cuenta con acceso a dicha atencio ́n m ́edica ba ́sica. Esta problema ́tica puede ser resuelta estableciendo sistemas de telemedicina sobre la redes de datos disponibles en dichas localidades. Sin embargo, una limitante para el establecimiento efectivo de un sistema de telemedicina son las tasas de datos ofrecidas por dichas redes. Por ejemplo, aun y cuando en la actualidad existen estetoscopios digitales que permiten la transmisio ́n de sen ̃ales de audio cardiaco sobre redes de datos, el ancho de banda requerido hace que su utilizacio ́n sea prohibitiva cuando se consideran las capacidades ofrecidas por las redes de datos disponibles en localidades remotas de nuestro pa ́ıs. El presente trabajo de investigacio ́n tiene como objetivo encontrar un mecanismo que permita la transmisi ́on de sen ̃ales de audio cardiaco en redes inal ́ambricas con tasas de datos bajas/medianas. Se decidi ́o enfocarse en este tipo de sen ̃ales debido a que las enfermedades cardiovasculares son la segunda causa de mortalidad en M ́exico. Para ello se analizaron co ́decs de audio existentes para aplicarlos a sen ̃ales de audio cardio- rrespiratorio y realizar su compresi ́on y transmisi ́on. El uso de los c ́odecs para com- primir/transmitir audio cardiorrespiratorio no es trivial; esto debido a que la mayor ́ıa de los c ́odecs fueron desarrollados para otro tipo de aplicaciones y podr ́ıan introducir distorsiones en la sen ̃al que conlleven a un mal diagn ́ostico. En este sentido se evalu ́o el desempen ̃o de los co ́decs al codificar/decodificar sen ̃ales de audio cardiorrespiratorio para despu ́es comparar la sen ̃al resultante con la original mediante pruebas objetivas y preceptuales estandarizadas. Como resultado de estas pruebas se descartaron varios co ́decs, seleccionando u ́nicamente aquellos que arrojaron resultados satisfactorios en las pruebas. Posteriormente se analiz ́o la factibilidad de utilizar estos c ́odecs para la transmisio ́n de audio cardiorrespiratorio sobre redes inal ́ambricas con tasas de datos bajas/medianas. Para esto se analizaron las tramas generadas por dichos c ́odecs para Dr. Salvador Villarreal Reyes Director de Tesis posteriormente determinar un mecanismo de empaquetamiento y transmisi ́on sobre una red punto a punto con transceptores IEEE 802.15.4. Se evalu ́o la utilizaci ́on de los co ́decs en este tipo de redes por medio de simulacio ́n y utilizando una cama de pruebas f ́ısica con transceptores XBee Pro. Finalmente se realizaron pruebas sobre las sen ̃ales recibidas para dar una recomendaci ́on final respecto a los c ́odecs a utilizar para este tipo de aplicaciones. Las contribuciones de esta tesis pueden utilizarse como referencia para el establecimiento de un sistema de teleauscultaci ́on en redes de datos con anchos de banda limitados.},
author = {Castorena, L},
keywords = {audio cardiaco,compresi\'{o}n de audio,c\'{o}dec,redes de sensores,telemedicina},
school = {Centro de Investigaci\'{o}n Cient\'{\i}fica y Educaci\'{o}n Superior de Ensenada},
title = {{An\'{a}lisis y Adaptaci\'{o}n de c\'{o}decs para la transmisi\'{o}n de audio cardiaco sobre redes inal\'{a}mbricas con tasas de datos bajas/medianas}},
year = {2012}
}
@inproceedings{Noah1984,
abstract = {This paper introduces an approach to scalar quantization of LPC reflection coefficients which outperforms typical scalar quantization schemes using a squared-error distortion measure. As in vector quantization, an iterative algorithm is used to generate the source codebook. Scalar quantization produces a greater distortion, for a given number of bits- than vector quantization but reduced computation time and storage requirements make the Lloyd-Max approach economically attractive for implementation in real-time hardware. The algorithm is developed and a comparison with another scalar quantization scheme is made.},
author = {Noah, M.},
booktitle = {Acoustics, Speech, and Signal Processing, IEEE International Conference on ICASSP '84.},
doi = {10.1109/ICASSP.1984.1172446},
issn = {07367791},
pages = {29--32},
publisher = {IEEE},
title = {{Optimal Lloyd-Max quantization of LPC speech parameters}},
volume = {9},
year = {1984}
}
@article{Zhang1998b,
abstract = {The matching pursuit method of Mallat and Zhang is applied to the analysis and synthesis of phonocardiograms (PCG's). The method is based on a classical Gabor wavelet or time-frequency atom which is the product of a sinusoid and a Gaussian window function. It decomposes a signal into a series of time-frequency atoms by an iterative process based on selecting the largest inner product of the signal (and the subsequent residues) with atoms from a redundant dictionary. The Gaussian window controls the envelope duration and time position of each atom; and the sinusoid represents the frequency. The method was applied to two sets of PCG's: one with very low-noise level and the other with 10\% noise energy. Each data base includes 11 PCG's representing the normal and the pathological conditions of the heart. The normalized root-mean-square error (NRMSE) was computed between the original and the reconstructed signals. The results show that the matching pursuit method is very suitable to the transient and complex properties of the PCG's, as it yielded excellent NRMSE's around 2.2\% for the two sets of 11 PCG's tested.},
author = {Zhang, X and Durand, L G and Senhadji, L and Lee, H C and Coatrieux, J L},
doi = {10.1109/10.704865},
file = {:Users/roilhiibarra/Google Drive/tesis\_maestria\_roilhi/Bibliograf\'{\i}a/Art\'{\i}culos MP en PCG (1)/zhang98\_analysis\_synthesisPCGMP.pdf:pdf},
issn = {0018-9294},
journal = {IEEE transactions on bio-medical engineering},
keywords = {Computer-Assisted,Heart Murmurs,Heart Murmurs: diagnosis,Heart Sounds,Humans,Observer Variation,Phonocardiography,Reference Values,Reproducibility of Results,Signal Processing},
month = aug,
number = {8},
pages = {962--71},
pmid = {9691571},
title = {{Analysis-synthesis of the phonocardiogram based on the matching pursuit method}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/9691571},
volume = {45},
year = {1998}
}
@article{Painter2000,
abstract = {During the last decade, CD-quality digital audio has essentially replaced analog audio. Emerging digital audio applications for network, wireless, and multimedia computing systems face a series of constraints such as reduced channel bandwidth, limited storage capacity, and low cost. These new applications have created a demand for high-quality digital audio delivery at low bit rates. In response to this need, considerable research has been devoted to the development of algorithms for perceptually transparent coding of high-fidelity (CD-quality) digital audio. As a result, many algorithms have been proposed, and several have now become international and/or commercial product standards. This paper reviews algorithms for perceptually transparent coding of CD-quality digital audio, including both research and standardization activities. This paper is organized as follows. First, psychoacoustic principles are described, with the MPEG psychoacoustic signal analysis model 1 discussed in some detail. Next, filter bank design issues and algorithms are addressed, with a particular emphasis placed on the modified discrete cosine transform, a perfect reconstruction cosine-modulated filter bank that has become of central importance in perceptual audio coding. Then, we review methodologies that achieve perceptually transparent coding of FM- and CD-quality audio signals, including algorithms that manipulate transform components, subband signal decompositions, sinusoidal signal components, and linear prediction parameters, as well as hybrid algorithms that make use of more than one signal model. These discussions concentrate on architectures and applications of those techniques that utilize psychoacoustic models to exploit efficiently masking characteristics of the human receiver. Several algorithms that have become international and/or commercial standards receive in-depth treatment, including the ISO/IEC MPEG family (-1, -2, -4), the Lucent Technologies PAC/EPAC/MPAC, the Dolby AC-2/AC-3, and the Sony ATRAC/SDDS algorithms. Then, we describe subjective evaluation methodologies in some detail, including the ITU-R BS.1116 recommendation on subjective measurements of small impairments. This paper concludes with a discussion of future research directions},
author = {Painter, Ted and Spanias, Andreas},
doi = {10.1109/5.842996},
isbn = {0018-9219},
issn = {00189219},
journal = {Proceedings of the IEEE},
keywords = {AC-2,AC-3,AT R AC,Advanced audio coding (AAC),Audio coding,Audio coding standards,Audio signal processing,Data compression,Digital audio radio (DAR),Digital broadcast audio (DBA),Filter banks,High-definition tv (HDTV),MPEG},
number = {4},
pages = {451--515},
title = {{Perceptual coding of digital audio}},
volume = {88},
year = {2000}
}
@article{wang04,
abstract = {In this study, the matching pursuit method (MP) was used to decompose the second heart sound S2 into a series of time-frequency atoms. From these parameterized atoms, A2 and P2 can be separated. The first two dominant frequencies of A2 were identified and used as features of a linear classifier to diagnose aortic valve abnormality. This method was applied to two sets of S2 data recorded from 28 patients with normal, and 3-4 patients with abnormal, bioprosthetic aortic valves respectively, it was found that the values of both features exhibit significant differences between the normal and abnormal set (p< 5.0e-8). Using these two features, a correct classification of 90.3\% was obtained. In addition, when the Wigner distribution of S2 was calculated from the decomposed atoms and compared with a spectrogram of S2, the MP method provided better results. The study demonstrates that the MP method may be promising technique for heart sound analysis.},
author = {Wang, W and Pan, J},
journal = {Signal Processing, 2004. Proceedings. ICSP'04. 2004 7th International Coference on},
keywords = {aortic valve abnormality,heart sound analysis,matching pursuit,signal decomposition,time-frequency analysis,time-frequency atom},
pages = {2229--2232},
title = {{Decomposition and analysis of the second heart sound based on the matching pursuit method}},
volume = {3},
year = {2004}
}
@inproceedings{Wolfe2001,
abstract = {We consider the construction of multiresolution Gabor dictionaries appropriate for audio signal analysis. Motivated by a desire for parsimony and efficiency, we propose and formalise the idea of reduced multi-Gabor systems, showing that they constitute a frame for L2 (R) and other Hilbert spaces of interest. In order to demonstrate the practicality of such a scheme, we apply it to the atomic decomposition of music and speech signals observed in noise. Qualitative results indicate the potential of this method to yield a salient representation of typical audio signals while at the same time reducing computational costs as compared to a full multiresolution decomposition},
author = {Wolfe, P.J. and Godsill, S.J. and Dorfler, M.},
booktitle = {Applications of Signal Processing to Audio and Acoustics, 2001 IEEE Workshop on the},
doi = {10.1109/ASPAA.2001.969538},
isbn = {0-7803-7126-7},
pages = {43--46},
publisher = {IEEE},
title = {{Multi-Gabor dictionaries for audio time-frequency analysis}},
year = {2001}
}
@article{Plumbley2010,
abstract = {Sparse representations have proved a powerful tool in the analysis and processing of audio signals and already lie at the heart of popular coding standards such as MP3 and Dolby AAC. In this paper we give an overview of a number of current and emerging applications of sparse representations in areas from audio coding, audio enhancement and music transcription to blind source separation solutions that can solve the ??cocktail party problem.?? In each case we will show how the prior assumption that the audio signals are approximately sparse in some time-frequency representation allows us to address the associated signal processing task.},
author = {Plumbley, Mark D. and Blumensath, Thomas and Daudet, Laurent and Gribonval, R\'{e}mi and Davies, Mike E.},
doi = {10.1109/JPROC.2009.2030345},
isbn = {0018-9219},
issn = {00189219},
journal = {Proceedings of the IEEE},
keywords = {Audio coding,Basis functions,Discrete cosine transforms,Fourier transforms,Music,Signal representations,Wavelet transforms},
number = {6},
pages = {995--1005},
title = {{Sparse representations in audio and music: From coding to source separation}},
volume = {98},
year = {2010}
}
@book{Jayant1974,
abstract = {A study is presented on the digital coding of speech by means of a straightforward approximation of the time waveform. In particular, the closely related discrete-time discrete-amplitude signal representations that are rather well known as pulse-code modulation (PCM), differential pulse-code modulation (DPCM), and delta modulation (DM) are discussed. Speech is recognized as a nonstationary signal, and emphasis is therefore placed on "companding" and "adaptive" strategies for waveform quantization and prediction. With signal-to-quantization-error ratio SNR as a performance measure, techniques are suggested which are most likely to be appropriate for given specifications of information rate. It is pointed out that error waveforms in speech quantization cannot be regarded as additive white noise, in general. This means that for finer assessments of speech coders, either relative or absolute, one needs to supplement SNR-based observations with corrections for subjective and perceptual factors. The latter seem to defy quantification as a rule. Invaluable, therefore, are explicit preference tests for direct comparisons of coders from a perceptual standpoint, and notions such as isopreference and multidimensional scaling are naturally appropriate in interpreting the results of such tests. Final points of concern are communication questions such as multiple encodings of speech by tandem coder-decoder pairs; conversions among different digital code formats; and the effects of additive and multiplicative noise in the communication channel, as manifest in the erroneous reception of speech-carrying bits. Information on these topics tends to be heterogeneous and nontheoretical, and the present digression into the subject is cursory by intent. The gramophone record accompanying this paper demonstrates some of the manipulations of speech that are discussed.},
author = {Jayant, Nuggehally S.},
booktitle = {Proceedings of the IEEE},
doi = {10.1109/PROC.1974.9484},
isbn = {0-13-211913-7 01},
issn = {00189219},
publisher = {Prentice Hall},
title = {{Digital Coding of Waveforms. Principles and applications to speech and video.}},
volume = {62},
year = {1974}
}
@book{Zolzer2011,
abstract = {The aim of the project and this book is to present the main fields of digital audio effects.},
author = {Z\"{o}lzer, Udo},
booktitle = {DAFX: Digital Audio Effects: Second Edition},
doi = {10.1002/9781119991298},
isbn = {9780470665992},
publisher = {John Wiley \& Sons, Inc.},
title = {{DAFX: Digital Audio Effects: Second Edition}},
year = {2011}
}
@techreport{Who2012,
abstract = {Has top 20 causes of death in 2004 and 2030. burdenofdisease},
archivePrefix = {arXiv},
arxivId = {0010011010011},
author = {WHO},
booktitle = {WHO World Health Organization},
doi = {10.2307/3348165},
eprint = {0010011010011},
institution = {World Health Organization},
isbn = {0010011010011},
pages = {171},
title = {{World Health Statistics}},
url = {http://books.google.com/books?hl=en\&amp;lr=\&amp;id=osms0oMN\_qwC\&amp;oi=fnd\&amp;pg=PA7\&amp;dq=World+Health+Statistics\&amp;ots=iZU1J3AqjI\&amp;sig=sIBAWCK7qn9DYyQU\_cHVERTK4Ks},
volume = {27},
year = {2012}
}
@article{Sturbe1980,
author = {Sturbe, Hans},
file = {:Users/roilhiibarra/Google Drive/strube88\_linear\_prediction\_warped\_freqscale.pdf:pdf},
journal = {The Journal of the Acoustical Society of America},
number = {4},
pages = {1071--1076},
title = {{Linear prediction on a warped frequency scale}},
volume = {68},
year = {1980}
}
@inproceedings{Djebbari2000,
abstract = {In this paper, we present results of the PCG (phonocardiogram) signal analysis using the STFT (Short-Time Fourier Transform). Because of the nonstationarity of the PCG signal, it is important to maintain an analysing time window as short as possible to guaranty the stationarity hypothesis over small analysed segments. This will reduce the frequency resolution of the resulting spectrogram. However by adjusting the sliding time window, we can reach an acceptable result. The spectrogram is calculated by using first, short length sliding window to generate a temporal representation of the PCG, then longer length sliding window in order to generate a spectral representation of the PCG power. The resolution in such representations depend directly on the sliding window length. The temporal representation allows heart sounds and cardiac cycle durations to be measured. Whereas the spectrum, assuming a good frequency resolution, allows spectral characterisation of each heart sound. The results we obtained on normal PCG signal, show that the STFT analysis provides a clear comprehension of the cardiac events when the spectra are represented in the time-frequency scale basis. Such results confirm the normal aspects of the analysed PCG signal},
author = {Djebbari, Abdelghani and Reguig, Fethi Bereksi},
booktitle = {Electronics, Circuits and Systems, 2000. IECS 2000. The 7th IEEE International Conference on},
doi = {10.1109/ICECS.2000.913008},
isbn = {0780365429},
pages = {844--847},
publisher = {IEEE},
title = {{Short-time fourier transform analysis of the phonocardiogram signal}},
volume = {2},
year = {2000}
}
@article{Wood1992,
abstract = {This study employed a new analytical tool, the Binomial joint time-frequency transform, to test the hypothesis that first heart sound frequency rises during the isovolumic contraction period. Cardiac vibrations were recorded from eight open chest dogs using an ultralight accelerometer cemented directly to the epicardium of the anterior left ventricle. The frequency response of the recording system was flat +/- 3 dB from 0.1 to 400 Hz. Three characteristic time-frequency spectral patterns were evident in the animals investigated: 1) A frequency component that rose from approximately 40-140 Hz in a 30-50 ms interval immediately following the ECG R-wave. 2) A slowly varying or static frequency of 60-100 Hz beginning midway through the isovolumic contraction period. 3) Broad-band peaks occurring at the time of the Ia and Ib high frequency components. The presence of rapid frequency dynamics limits the usefulness of stationary analysis techniques for the first heart sound. The Binomial transform provided much better resolution than the spectrograph or spectrogram, the two most common non-stationary signal analysis techniques. By revealing the onset and dynamics of first heart sound frequencies, time-frequency transforms may allow mechanical assessment of individual cardiac structures.},
author = {Wood, J. C. and Buda, A. J. and Barry, D. T.},
doi = {10.1109/10.142648},
isbn = {0018-9294},
issn = {00189294},
journal = {Biomedical Engineering, IEEE Transactions on},
number = {7},
pages = {730--740},
pmid = {1516940},
title = {{Time-frequency transforms: A new approach to first heart sound frequency dynamics}},
volume = {39},
year = {1992}
}
@inproceedings{Koishida1996,
abstract = {This paper presents a CELP speech coding system based on mel-generalized cepstral analysis. In the mel-generalized cepstral analysis, we can vary the model spectrum continuously from AR to cepstral modeling by changing the value of a parameter \&amp;gamma; and we can choose an appropriate model spectrum. Furthermore, the spectrum represented by mel-generalized cepstrum has frequency resolution similar to that of human ear. Since the perceptual weighting and postfiltering are carried out through the mel-generalized cepstrum, we expect the perceptual performance of the proposed coder to be improved. The subjective performance test indicates that the quality of the proposed CELP coder is about 2 dB higher than that of the conventional one},
author = {Koishida, K. and Tokuda, K. and Kobayashi, T. and Imai, S.},
booktitle = {Spoken Language, 1996. ICSLP '96 Proceedings., Fourth International Conference on},
doi = {10.1109/ICSLP.1996.607117},
isbn = {0-7803-3555-4},
pages = {318--321},
publisher = {IEEE},
title = {{CELP coding system based on mel-generalized cepstral analysis}},
volume = {1},
year = {1996}
}
@article{Daumer1982,
abstract = {The voice quality of several 9.6 - 32 kbit/s coders is determined with an extensive set of subjective listening tests. Single encodings of \&amp;\#956;255 PCM, adaptive differential PCM (ADPCM), subband coding (SBC), vocoder-driven adaptive transform coding (ATC), adaptive predictive coding (APC), and time domain harmonic scaling combined with SBC are compared in an idealized situation, that is, no added impairments. It is shown that single encodings of modest complexity 32 kbit/s coders such as ADPCM and SBC and more complex 24 kbit/s coders such as vocoder-driven ATC and APC offer quality nearly equivalent to 64 kbit/s \&amp;\#956;255 PCM. However, these conclusions are drawn in the absence of a realistic telephone network where tandem encodings, delay limitations, and nonvoice signals exist. Tandem encodings of 64 kbit/s \&amp;\#956;255 PCM, 32 kbit/s ADPCM, 16 kbit/s SBC, and 16 kbit/s APC are also evaluated. These 32 kbit/s and 16 kbit/s coders offer degraded tandem performance as compared to 64 kbit/s PCM, with the exception of synchronous tandeming of 32 kbit/s ADPCM with 64 kbit/s PCM where several encodings are subjectively equivalent to a single encoding of 32 kbit/s ADPCM.},
author = {Daumer, W.},
doi = {10.1109/TCOM.1982.1095508},
issn = {0090-6778},
journal = {IEEE Transactions on Communications},
number = {4},
pages = {665--662},
title = {{Subjective Evaluation of Several Efficient Speech Coders}},
volume = {30},
year = {1982}
}
@incollection{OReilly1984,
author = {O'Reilly, J.J.},
booktitle = {Telecommunication Principles},
pages = {86--96},
publisher = {Springer},
title = {{Pulse Code Modulation}},
year = {1984}
}
@article{Atal1971,
abstract = {We describe a procedure for efficient encoding of the speech wave by representing it in terms of time-varying parameters related to the transfer function of the vocal tract and the characteristics of the excitation. The speech wave, sampled at 10 kHz, is analyzed by predicting the present speech sample as a linear combination of the 12 previous samples. The 12 predictor coefficients are determined by minimizing the mean-squared error between the actual and the predicted values of the speech samples. Fifteen parameters$\backslash$\&$\backslash$\#151;namely, the 12 predictor coefficients, the pitch period, a binary parameter indicating whether the speech is voiced or unvoiced, and the rms value of the speech samples$\backslash$\&$\backslash$\#151;are derived by analysis of the speech wave, encoded and transmitted to the synthesizer. The speech wave is synthesized as the output of a linear recursive filter excited by either a sequence of quasiperiodic pulses or a white-noise source. Application of this method for efficient transmission and storage of speech signals as well as procedures for determining other speech characteristics, such as formant frequencies and bandwidths, the spectral envelope, and the autocorrelation function, are discussed.},
author = {Atal, Bishnu and Hanauer, Suzanne L.},
doi = {10.1121/1.1912679},
issn = {00014966},
journal = {The Journal of the Acoustical Society of America},
keywords = {6820,model,speech},
number = {2B},
pages = {637--655},
title = {{Speech Analysis and Synthesis by Linear Prediction of the Speech Wave}},
url = {http://dx.doi.org/10.1121/1.1912679},
volume = {50},
year = {1971}
}
@article{Haar1911,
abstract = {Die S\"{a}tze von it Cantor und it Du Bois-Reymond aus der Theorie der trigonometrischen Reihen werden auf beliebige it Sturm-Liouvillesche Reihen \"{u}bertragen; der Beweis wird so gef\"{u}hrt, da\ss die it Sturm-Liouvillesche Reihe mit H\"{u}lfe einer scharfen, von it Hobson herr\"{u}hrenden asymptotischen Darstellung der in ihnen auftretenden Entwicklungsfunktionen im wesentlichen auf eine trigonometrische zur\"{u}ckgef\"{u}hrt wird.},
author = {Haar, Alfred},
doi = {10.1007/BF01456927},
isbn = {0025583114321807},
issn = {00255831},
journal = {Mathematische Annalen},
number = {3},
pages = {331--371},
title = {{Zur Theorie der orthogonalen Funktionensysteme}},
volume = {69},
year = {1910}
}
@article{Leatham1987,
abstract = {Images: Fig 2: Fig 3: Fig 4: Fig 6: Fig 7: Fig 8: Fig 9:},
author = {Leatham, A},
doi = {10.1136/hrt.57.5.397},
issn = {1355-6037},
journal = {British heart journal},
number = {5},
pages = {397--403},
pmid = {3297119},
title = {{Auscultation and phonocardiography: a personal view of the past 40 years}},
volume = {57},
year = {1987}
}
@article{Debbal2006,
abstract = {This paper describes a signal processing technique aimed at$\backslash$ncomplementing cardiac auscultation in the detection of heart valve$\backslash$ndisease. The method provides a means for keeping objective records by$\backslash$nanalyzing the characteristics of the cardiac murmurs. The Short-time$\backslash$nFourier Transform (STFT) is used here to provide a graphic$\backslash$nrepresentation of the time-frequency information of the cardiac murmurs$\backslash$nfrom eight different pathology cases. The graphic representation$\backslash$nobtained shows the variation in frequency and intensity during the$\backslash$nmurmur. Some interesting observations show characteristic rising and$\backslash$nfalling tones, suggesting degrees of the pathology severity.},
author = {Debbal, S. M. and Bereksi-Reguig, F.},
doi = {10.1142/S0219519406001959},
issn = {0219-5194},
journal = {Journal of Mechanics in Medicine and Biology},
number = {03},
pages = {273--284},
title = {{Cardiac Murmur Analysis Using the Short-Time Fourier Transform}},
volume = {6},
year = {2006}
}
@article{Noll1997,
abstract = {The Moving Pictures Expert Group (MPEG) within the International Organization of Standardization (ISO) has developed a series of audio-visual standards known as MFEG-1 and MPEG-2. These audio-coding standards are the first international standards in the field of high-quality digital audio compression. MPEG-1 covers coding of stereophonic audio signals at high sampling rates aiming at transparent quality, whereas MPEG-2 also offers stereophonic audio coding at lower sampling rates. In addition, MPEG-2 introduces multichannel coding with and without backwards compatibility to MPEG-1 to provide an improved acoustical image for audio-only applications and for enhanced television and video-conferencing systems. MPEG-2 audio coding without backwards compatibility, called IMPEG-2 Advanced Audio Coding (AAC), offers the highest compression rates. Typical application areas for MPEG-based digital audio are in the fields of audio production, program distribution and exchange, digital sound broadcasting, digital storage, and various multimedia applications. We describe in some detail the key technologies and main features of MPEG-1 and MPEG-2 audio coders. We also present the MPEG-4 standard and discuss some of the typical applications for MPEG audio compression},
author = {Noll, P},
doi = {10.1109/79.618009},
issn = {1053-5888},
journal = {Signal Processing Magazine, IEEE},
keywords = {Hi-Fi equipment,ISO standards,audio coding,channel},
number = {5},
pages = {59--81},
title = {{MPEG digital audio coding}},
volume = {14},
year = {1997}
}
@article{koymen87,
author = {K\"{o}ymen, Hayrettin and Altay, Bulent K. and Ziya, Ider. Y.},
doi = {10.1109/TBME.1987.326006},
file = {:Users/roilhiibarra/Google Drive/tesis\_maestria\_roilhi/Bibliograf\'{\i}a/koymen87\_study\_of\_heartvalveSounds.pdf:pdf},
journal = {Biomedical Engineering, IEEE Transactions on},
keywords = {acoustical engineering,auditory implants,frequency estimation,heart valves,medical diagnostic imaging},
number = {11},
pages = {853--863},
title = {{A study of Prosthetic Heart Valve Sounds}},
volume = {BME-43},
year = {1987}
}
@inproceedings{Martinez-Alajarin2006,
abstract = {A general purpose system for telediagnosis of the valvular condition of the heart by analysing the phonocardiographic (PCG) signals generated by the heart is presented in this article. The system includes two main parts: a processing stage and a compression stage. The first one is arranged as a modular hierarchical structure with different abstraction levels, and performs a complete analysis of the PCG from the acquisition to the final diagnosis, following an event-based methodology. Analysis does not use auxiliary signals like ECG or pulse. The compression stage includes a lossy compression wavelet-based method with optimized parameters for an efficient transmission and storing of PCG signals. Results show a high degree of cardiac cycles in which all the events have been correctly delimited and identified, 91.27\% and 65.65\% for non-murmurs and for murmurs recordings, respectively, and compression rates between 2.6 and 5.6 times higher than the OGG Vorbis compression method.},
author = {Martinez-Alajarin, J. and Lopez-Candel, J. and Ruiz-Merino, R.},
booktitle = {Computers in Cardiology, 2006},
file = {:Users/roilhiibarra/Google Drive/tesis\_maestria\_roilhi/Bibliografía/articulos\_relacionados/martinez06\_ASEPTIC.pdf:pdf},
isbn = {978-1-4244-2532-7},
issn = {02766574},
pages = {537--540},
publisher = {IEEE},
title = {{ASEPTIC: Aided system for event-based phonocardiographic telediagnosis with integrated compression}},
year = {2006}
}
@article{Quatieri1985,
abstract = {This paper presents a new speech analysis/synthesis technique based on a sinusoidal representation of the speech production mechanism but which is independent of pitch and the voiced/unvoiced speech state. The resulting synthetic speech preserves the waveform shape and is essentially perceptually indistinguishable from the original. The method provides the basis for a general class of speech transformations and is successfully applied to time-scale modification, frequency scaling, and scaling of pitch. Furthermore, these modifications can be performed with a time-varying rate of change, allowing, for example, continuous adjustment of a speaker's fundamental frequency and rate of articulation. Although the analysis/synthesis system was originally designed for single-speaker signals, it is equally capable of recovering and modifying nonspeech signals such as music, multi-speakers, marine biologic sounds, and speech in the presence of interferences such as noise and musical backgrounds.},
author = {Quatieri, T. and McAulay, R.},
doi = {10.1109/ICASSP.1985.1168380},
isbn = {0096-3518},
issn = {0096-3518},
journal = {Acoustics, Speech, and Signal Processing, IEEE Transactions on},
number = {6},
pages = {1449--1464},
pmid = {1685235},
title = {{Speech transformations based on a sinusoidal representation}},
volume = {34},
year = {1986}
}
@article{McAulay1986,
abstract = {A sinusoidal model for the speech waveform is used to develop a new analysis/synthesis technique that is characterized by the amplitudes, frequencies, and phases of the component sine waves. These parameters are estimated from the short-time Fourier transform using a simple peak-picking algorithm. Rapid changes in the highly resolved spectral components are tracked using the concept of "birth" and "death" of the underlying sine waves. For a given frequency track a cubic function is used to unwrap and interpolate the phase such that the phase track is maximally smooth. This phase function is applied to a sine-wave generator, which is amplitude modulated and added to the other sine waves to give the final speech output. The resulting synthetic waveform preserves the general waveform shape and is essentially perceptually indistinguishable from the original speech. Furthermore, in the presence of noise the perceptual characteristics of the speech as well as the noise are maintained. In addition, it was found that the representation was sufficiently general that high-quality reproduction was obtained for a larger class of inputs including: two overlapping, superposed speech waveforms; music waveforms; speech in musical backgrounds; and certain marine biologic sounds. Finally, the analysis/synthesis system forms the basis for new approaches to the problems of speech transformations including time-scale and pitch-scale modification, and midrate speech coding [8], [9].},
author = {McAulay, R. and Quatieri, T.},
doi = {10.1109/TASSP.1986.1164910},
isbn = {0096-3518 VO - 34},
issn = {0096-3518},
journal = {Acoustics, Speech, and Signal Processing, IEEE Transactions on},
number = {4},
pages = {744--754},
title = {{Speech analysis/Synthesis based on a sinusoidal representation}},
volume = {34},
year = {1986}
}
@book{Vaidyanathan2008,
abstract = {Linear prediction theory has had a profound impact in the field of digital signal processing. Although the theory dates back to the early 1940s, its influence can still be seen in applications today. The theory is based on very elegant mathematics and leads to many beautiful insights into statistical signal processing. Although prediction is only a part of the more general topics of linear estimation, filtering, and smoothing, this book focuses on linear prediction. This has enabled detailed discussion of a number of issues that are normally not found in texts. For example, the theory of vector linear prediction is explained in considerable detail and so is the theory of line spectral processes. This focus and its small size make the book different from many excellent texts which cover the topic, including a few that are actually dedicated to linear prediction. There are several examples and computer-based demonstrations of the theory. Applications are mentioned wherever appropriate, but the focus is not on the detailed development of these applications. The writing style is meant to be suitable for self-study as well as for classroom use at the senior and first-year graduate levels. The text is self-contained for readers with introductory exposure to signal processing, random processes, and the theory of matrices, and a historical perspective and detailed outline are given in the first chapter.},
author = {Vaidyanathan, P. P.},
booktitle = {Synthesis Lectures on Signal Processing},
doi = {10.2200/S00086ED1V01Y200712SPR03},
pages = {198},
publisher = {Morgan \& Claypool},
title = {{The theory of linear prediction}},
url = {http://www.morganclaypool.com/doi/pdf/10.2200/S00086ED1V01Y200712SPR003},
year = {2008}
}
@phdthesis{Candeas2006,
author = {Candeas, P.V.},
school = {Universidad de Alcal\'{a}},
title = {{Desarrollo de t\'{e}cnicas de codificaci\'{o}n de audio basadas en modelos de se\~{n}al param\'{e}tricos}},
url = {http://hdl.handle.net/10017/783},
year = {2006}
}
@article{Mermelstein1988,
abstract = {CCITT Study Group XVIII recognized the need for a new international coding standard on high-quality audio to allow interconnection of diverse switching, transmission, and terminal equipment and organized an expert group in 1983 to recommend an appropriate coding technique. A tutorial discussion is provided of the adaptive differential PCM (pulse-code modulation) coding method recommended by the group. The discussion covers the subjective performance tests performed, mode initialization and mode switching, data-speed multiplexing, and communication between narrowband and wideband terminals},
author = {Mermelstein, Paul},
doi = {10.1109/35.417},
issn = {01636804},
journal = {Communications Magazine, IEEE},
number = {1},
pages = {8--15},
title = {{G. 722: a new CCITT coding standard for digital transmission of wideband audio signals}},
volume = {26},
year = {1988}
}
@book{Hayes96,
abstract = {The main thrust is to provide students with a solid understanding of a number of important and related advanced topics in digital signal processing such as Wiener filters, power spectrum estimation, signal modeling and adaptive filtering. Scores of worked examples illustrate fine points, compare techniques and algorithms and facilitate comprehension of fundamental concepts. Also features an abundance of interesting and challenging problems at the end of every chapter.},
author = {Hayes, Monson H.},
booktitle = {Technometrics},
doi = {10.2307/1271141},
isbn = {0471594318},
issn = {00401706},
publisher = {John Wiley \& Sons},
title = {{Statistical Digital Signal Processing and Modeling}},
volume = {39},
year = {2009}
}
@phdthesis{Nieblas2014,
abstract = {The goal of this thesis is the development of signal processing tools to adequately model the structure of the heart sound signal in order to be compressed. A theoretical and experimental study of the low representation is presented through the algorithm matching pursuit (MP) using different time-frequency dictionaries for the compression of heart sound signal. Of special interest is the possibility of generating the dictionary that best models the characteristics of cardiac sound signals. Such dictionary allows us to compress and segment heart sounds, that is, to detect the beginning and end of each sound. Once compressed, the quality of audio signals heart is assessed via subjective listening tests in order to quantify the distortion introduced by sparse signal representation. During the subjective listening tests, preliminary results suggest that participants have a sightly better preference for the proposed compression scheme over state-of-the-art algorithms such as MPEG Layer 3.},
author = {Nieblas, Carlos I.},
file = {:Users/roilhiibarra/Google Drive/tesis\_maestria\_roilhi/Tesis\_CNieblas.pdf:pdf},
keywords = {Gabor atoms,Matching pursuit algorithm,compression of the heart sounds.,sparse representation},
school = {Centro de Investigaci\'{o}n Cient\'{\i}fica y Eduaci\'{o}n Superior de Ensenada},
title = {{Compresi\'{o}n del audio cardiaco mediante diccionarios redundantes y codificaci\'{o}n escasa: aplicaci\'{o}n a la transmisi\'{o}n en redes de sensores}},
type = {Tesis de maestr\'{\i}a},
year = {2014}
}
@article{Gribonval2003,
abstract = {The purpose of this correspondence is to generalize a result by Donoho and Huo and Elad and Bruckstein on sparse representations of signals in a union of two orthonormal bases for RN. We consider general (redundant) dictionaries for RN, and derive sufficient conditions for having unique sparse representations of signals in such dictionaries. The special case where the dictionary is given by the union of L\&ge;2 orthonormal bases for RN is studied in more detail. In particular, it is proved that the result of Donoho and Huo, concerning the replacement of the \&\#8467;0 optimization problem with a linear programming problem when searching for sparse representations, has an analog for dictionaries that may be highly redundant.},
author = {Gribonval, R\'{e}mi and Nielsen, Morten},
doi = {10.1109/TIT.2003.820031},
isbn = {0018-9448},
issn = {00189448},
journal = {Information Theory, IEEE Transactions on},
keywords = {Dictionaries,Grassmannian frames,Linear programming,Mutually incoherent bases,Nonlinear approximation,Sparse representations},
number = {12},
pages = {3320--3325},
title = {{Sparse Representations in Unions of Bases}},
volume = {49},
year = {2003}
}
@misc{Hummersone2011,
author = {Hummersone, Chris},
title = {{MUSHRA test GUI}},
url = {http://iosr.surrey.ac.uk/software},
year = {2011}
}
@book{Elad2010,
abstract = {This textbook introduces sparse and redundant representations with a focus on applications in signal and image processing. The theoretical and numerical foundations are tackled before the applications are discussed. Mathematical modeling for signal sources is discussed along with how to use the proper model for tasks such as denoising, restoration, separation, interpolation and extrapolation, compression, sampling, analysis and synthesis, detection, recognition, and more. The presentation is elegant and engaging. Sparse and Redundant Representations is intended for graduate students in applied mathematics and electrical engineering, as well as applied mathematicians, engineers, and researchers who are active in the fields of signal and image processing.},
archivePrefix = {arXiv},
arxivId = {g},
author = {Elad, Michael},
booktitle = {Sparse and Redundant Representations: From Theory to Applications in Signal and Image Processing},
doi = {10.1007/978-1-4419-7011-4},
eprint = {g},
isbn = {978-1-4419-7010-7},
pmid = {16351060},
publisher = {Springer},
title = {{Sparse and Redundant Representations: from theory to applications in signal and image processing}},
url = {http://www.springerlink.com/index/10.1007/978-1-4419-7011-4$\backslash$nhttp://link.springer.com/10.1007/978-1-4419-7011-4},
year = {2010}
}
@inproceedings{McLoughlin2000,
abstract = {This paper proposes a novel speech codec named the Chinese RPE-LTP (CRPE-LTP), which exploits some of the unique characteristics of Mandarin in speech in order to improve speech quality, for Mandarin speakers. Although the codec is based on the proven principles of the GSM06.10 RPE-LTP coder; its performance is better than that of GSM for coding Mandarin speech, and is designed to at least match GSM performance for coding English speech},
author = {McLoughlin, I. and Zhong-Qiang, Ding Zhong-Qiang Ding},
booktitle = {Circuits and Systems, 2000. IEEE APCCAS 2000. The 2000 IEEE Asia-Pacific Conference on},
doi = {10.1109/APCCAS.2000.913628},
isbn = {0-7803-6253-5},
pages = {748--751},
publisher = {IEEE},
title = {{Mandarin speech coding using a modified RPE-LTP technique}},
year = {2000}
}
@inproceedings{Gu1995,
abstract = {One of the primary objectives in the design of digital portable radio is power reduction required to maximize run time and minimize battery size and weight. Available power saving strategies such as dynamic power level control and discontinuous transmission are limited in their scope. A more effective approach is to operate the processors at the lowest supply voltage without incurring reduction in the throughput. Parallel architecture utilizing pipelining and parallelism through hardware duplication can be used to maintain throughput at lower voltages, by allowing slower device speeds. In the paper, several parallel/pipelined implementations of a VSELP speech coder employing VSELP algorithm modifications are suggested and are assessed for the power saving-voice quality trade-off},
author = {Gu, Zhenzhong Gu Zhenzhong and Sudhakar, R. and Lee, E.K.B.},
booktitle = {Southcon '95. Conference Record},
doi = {10.1109/SOUTHC.1995.516098},
isbn = {0-7803-2576-1},
pages = {176--181},
publisher = {IEEE},
title = {{Energy efficient DSP architectures for VSELP speech coder}},
year = {1995}
}
@article{Abbas2009,
abstract = {The auscultation method is an important diagnostic indicator for hemodynamic anomalies. Heart sound classification and analysis play an important role in the auscultative diagnosis. The term phonocardiography refers to the tracing technique of heart sounds and the recording of cardiac acoustics vibration by means of a microphone-transducer. Therefore, understanding the nature and source of this signal is important to give us a tendency for developing a competent tool for further analysis and processing, in order to enhance and optimize cardiac clinical diagnostic approach. This book gives the reader an inclusive view of the main aspects in phonocardiography signal processing.},
author = {Abbas, Abbas K. and Bassam, Rasha},
doi = {10.2200/S00187ED1V01Y200904BME031},
file = {:Users/roilhiibarra/Google Drive/tesis\_maestria\_roilhi/Bibliografía/articulos\_relacionados/Abbas09\_PCG\_signal\_processing.pdf:pdf},
isbn = {9781598299755},
issn = {1930-0328},
journal = {Synthesis Lectures on Biomedical Engineering},
keywords = {PCG classification,Phonocardiography,Phonocardiography calibration,Signal Processing,Stethoscope microphone,auscultation technique,cardiac acoustic imaging,heart sounds,signal filtering,spectral estimation and analysis},
number = {1},
pages = {1--194},
publisher = {Morgan \& Claypool},
title = {{Phonocardiography Signal Processing}},
volume = {4},
year = {2009}
}
@article{Huerta2001a,
abstract = {We present a method to reduce the degradation in recognition accuracy introduced by full-rate GSM RPE-LTP coding by combining sets of acoustic models trained under different distortion conditions. During recognition, the a posteriori probabilities of an utterance are calculated as a weighted sum of the posteriors corresponding to the individual models. The phonemes used by the system's word pronunciations are grouped into classes according to amount of distortion they undergo in coding. The acoustic model used in the decoding process is a weighted combination of models derived from clean speech and models derived from speech that had been degraded by GSM coding (the source models), with the relative combination of the two sources depending on the extent to which each class of phonemes is degraded by the coding process. To determine the distortion class membership, and hence the weights, we measure the spectral distortion introduced to the quantized long-term residual by the RPE-LTP codec. We discuss how this distortion varies according to phonetic class. The method described reduces the degradation in recognition accuracy introduced by GSM coding of sentences in the TIMIT database by more than 70\% relative to the baseline accuracy obtained in matched training and testing conditions with respect to a system using the source acoustic models, and up to 60\% relative to the best baseline systems regardless of the number of Gaussians.},
author = {Huerta, Juan M. and Stern, Richard M.},
doi = {10.1016/S0167-6393(00)00055-8},
isbn = {1412268710},
issn = {01676393},
journal = {Speech Communication},
number = {2},
pages = {213--225},
title = {{Distortion-class modeling for robust speech recognition under GSM RPE-LTP coding}},
volume = {34},
year = {2001}
}
@article{Gribonval2007,
abstract = {The purpose of this paper is to study sparse representations of signals from a general dictionary in a Banach space. For so-called localized frames in Hilbert spaces, the canonical frame coefficients are shown to provide a near sparsest expansion for several sparseness measures. However, for frames which are not localized, this no longer holds true and sparse representations may depend strongly on the choice of the sparseness measure. A large class of admissible sparseness measures is introduced, and we give sufficient conditions for having a unique sparse representation of a signal from the dictionary w.r.t. such a sparseness measure. Moreover, we give sufficient conditions on a signal such that the simple solution of a linear programming problem simultaneously solves all the nonconvex (and generally hard combinatorial) problems of sparsest representation of the signal w.r.t. arbitrary admissible sparseness measures. ?? 2006 Elsevier Inc. All rights reserved.},
author = {Gribonval, R. and Nielsen, M.},
doi = {10.1016/j.acha.2006.09.003},
isbn = {1063-5203},
issn = {10635203},
journal = {Applied and Computational Harmonic Analysis},
keywords = {Incoherent dictionary,Linear programming,Localized frame,Nonconvex optimization,Redundant dictionary,Sparse representation,Sparseness measure},
number = {3},
pages = {335--355},
title = {{Highly sparse representations from dictionaries are unique and independent of the sparseness measure}},
volume = {22},
year = {2007}
}
@article{Pelech2004,
abstract = {Cardiac auscultation remains a critical component of the pediatric examination and is the primary method of diagnosis for the common innocent murmurs of childhood. This article outlines the significance of auscultation and defines the skills important for the diagnosis and recognition of common cardiac murmurs in childhood. The origin of heart sounds and murmurs is reviewed, and an approach to pediatric murmur evaluation is presented. The seven innocent murmurs of childhood and adolescence are reviewed in detail. Further diagnostic evaluation and referral depends the clinician's confidence and experience in recognizing and correctly characterizing these murmurs.},
author = {Pelech, Andrew N.},
doi = {10.1016/j.pcl.2004.08.004},
issn = {00313955},
journal = {Pediatric Clinics of North America},
number = {6},
pages = {1515--1535},
pmid = {15561171},
title = {{The physiology of cardiac auscultation}},
volume = {51},
year = {2004}
}
@article{Doi2008,
abstract = {Computer-aided diagnosis (CAD) has become one of the major research subjects in medical imaging and diagnostic radiology. In this article, the motivation and philosophy for early development of CAD schemes are presented together with the current status and future potential of CAD in a PACS environment. With CAD, radiologists use the computer output as a "second opinion" and make the final decisions. CAD is a concept established by taking into account equally the roles of physicians and computers, whereas automated computer diagnosis is a concept based on computer algorithms only. With CAD, the performance by computers does not have to be comparable to or better than that by physicians, but needs to be complementary to that by physicians. In fact, a large number of CAD systems have been employed for assisting physicians in the early detection of breast cancers on mammograms. A CAD scheme that makes use of lateral chest images has the potential to improve the overall performance in the detection of lung nodules when combined with another CAD scheme for PA chest images. Because vertebral fractures can be detected reliably by computer on lateral chest radiographs, radiologists' accuracy in the detection of vertebral fractures would be improved by the use of CAD, and thus early diagnosis of osteoporosis would become possible. In MRA, a CAD system has been developed for assisting radiologists in the detection of intracranial aneurysms. On successive bone scan images, a CAD scheme for detection of interval changes has been developed by use of temporal subtraction images. In the future, many CAD schemes could be assembled as packages and implemented as a part of PACS. For example, the package for chest CAD may include the computerized detection of lung nodules, interstitial opacities, cardiomegaly, vertebral fractures, and interval changes in chest radiographs as well as the computerized classification of benign and malignant nodules and the differential diagnosis of interstitial lung diseases. In order to assist in the differential diagnosis, it would be possible to search for and retrieve images (or lesions) with known pathology, which would be very similar to a new unknown case, from PACS when a reliable and useful method has been developed for quantifying the similarity of a pair of images for visual comparison by radiologists.},
author = {Doi, Kunio},
doi = {10.1016/j.compmedimag.2007.02.002},
issn = {0895-6111},
journal = {Computerized medical imaging and graphics},
keywords = {20th Century,Computer-Assisted,Computer-Assisted: history,Computer-Assisted: utilization,Diagnosis,Diagnostic Imaging,Forecasting,History,Humans,Radiology Information Systems,United States},
number = {4-5},
pages = {198--211},
pmid = {17349778},
title = {{Computer-aided diagnosis in medical imaging: historical review, current status and future potential}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=1955762\&tool=pmcentrez\&rendertype=abstract},
volume = {31},
year = {2008}
}
@article{Gabor1946,
abstract = {The purpose .of these three studies is an inquiry into the essence of the "information" conveyed by channels of communication, and the application of the results of this inquiry to the practical problem of optimum utilization of frequency bands.},
author = {Gabor, Dennis},
doi = {10.1049/ji-3-2.1946.0074},
isbn = {9781412806794},
issn = {2054-0604},
journal = {Journal of the Institution of Electrical Engineers-Part III: Radio and Communication Engineering},
number = {26},
pages = {429--441},
pmid = {21424025},
title = {{Theory of communication. Part 1: The analysis of information}},
url = {http://digital-library.theiet.org/deliver/fulltext/ji-1/94/73/19470015.pdf?itemId=/content/journals/10.1049/ji-1.1947.0015\&mimeType=pdf},
volume = {93},
year = {1946}
}
@inproceedings{Coleman1989,
abstract = {The planned pan-European cellular digital mobile radio (DMR) system will use a regular pulse excitation with long-term predictor (RPE-LTP), 13 kb/s codec. Four phases of experimentation were planned: (1) national preselection tests; (2) European selection tests; (3) optimization tests; and (4) verification and characterization tests with simulated burst-error patterns. The subjective listening tests adopted are described, and an outline of the performance of the RPE-LTP codec with other parts of the digital network is given. Some general guidance is also given on its performance with nonvoice services which include information and DTMF tones},
author = {Coleman, A. and Gleiss, N. and Sotscheck, J. and Usai, P. and Scheuermann, H.},
booktitle = {Global Telecommunications Conference and Exhibition Communications Technology for the 1990s and Beyond (GLOBECOM), 1989. IEEE},
doi = {10.1109/GLOCOM.1989.64123},
issn = {03932648},
pages = {1075--1079},
publisher = {IEEE},
title = {{Subjective performance evaluation of the RPE-LTP codec for the pan-European cellular digital mobile radio system}},
year = {1989}
}
@article{Roguin2006,
abstract = {Rene Theophile Hyacinthe La\"{e}nnec (1781-1826) was a French physician who, in 1816, invented the stethoscope. Using this new instrument, he investigated the sounds made by the heart and lungs and determined that his diagnoses were supported by the observations made during autopsies. La\"{e}nnec later published the first seminal work on the use of listening to body sounds, De L'auscultation Mediate (On Mediate Auscultation). La\"{e}nnec is considered the father of clinical auscultation and wrote the first descriptions of bronchiectasis and cirrhosis and also classified pulmonary conditions such as pneumonia, bronchiectasis, pleurisy, emphysema, pneumothorax, phthisis and other lung diseases from the sounds he heard with his invention. La\"{e}nnec perfected the art of physical examination of the chest and introduced many clinical terms still used today.},
author = {Roguin, Ariel},
doi = {10.3121/cmr.4.3.230},
isbn = {1539-4182 (Print)$\backslash$r1539-4182 (Linking)},
issn = {15394182},
journal = {Clinical Medicine and Research},
keywords = {Atrial systole,Laennec's cirrhosis,Mediate auscultation,Melanoma,Tuberculosis,Ventricular systole},
number = {3},
pages = {230--235},
pmid = {17048358},
title = {{Rene Theophile Hyacinthe Laennec (1781-1826): The man behind the stethoscope}},
volume = {4},
year = {2006}
}
@article{Boutana2011,
abstract = {Heart sounds that are multicomponent non-stationary signals characterise the normal phonocardiogram (PCG) signals and the pathological PCG signals. The time-frequency analysis is a powerful tool in the analysis of non-stationary signals especially for PCG signals. It permits detecting and characterising abnormal murmurs in the diagnosis of heart disease. In this study, the authors introduce a novel method based on time-frequency analysis in conjunction with a threshold evaluated on Renyi entropy for the segmentation and the analysis of PCG signals. The method was applied to different sets of PCG signals: early aortic stenosis, late systolic aortic stenosis, pulmonary stenosis and mitral regurgitation. The analysis has been conducted on real biomedical data. Tests performed proved the ability of the method for segmentation between the main components and the pathological murmurs of the PCG signal. Also, the method permits elucidating and extracting useful features for diagnosis and pathological recognition.},
author = {Boutana, D. and Benidir, M. and Barkat, B.},
doi = {10.1049/iet-spr.2010.0013},
issn = {17519675},
journal = {IET Signal Processing},
number = {6},
pages = {527--537},
title = {{Segmentation and identification of some pathological phonocardiogram signals using time-frequency analysis}},
volume = {5},
year = {2011}
}
@article{Wood1995,
abstract = {Quantitative phonocardiography has been limited by many factors: nonstandard nomenclature and recording techniques, complicated mechanoacoustic generation, propagation and coupling, and inherent heart sound nonstationarity. New nonstationary signal processing techniques provide a powerful tool for phonocardiography, particularly in regard to the first heart sound. Recent work supports the concept that the first heart sound is composed of valve-initiated myocardial traveling waves superimposed upon the acceleration of myocardial contraction. Clinically, nonstationary signal analysis has been most frequently applied toward the study of mechanical prosthetic valves. However, a better understanding of first heart sound mechanics may facilitate the diagnosis of myocardial and native-valve pathology. Given the inherent system complexity, an interdisciplinary approach incorporating physicians, mechanical engineers, seismologists, and electrical engineers is imperative},
author = {Wood, J.C. and Barry, D.T.},
doi = {10.1109/51.376751},
issn = {0739-5175},
journal = {Engineering in Medicine and Biology Magazine, IEEE},
number = {2},
pages = {144--151},
title = {{Time-frequency analysis of the first heart sound}},
volume = {14},
year = {1995}
}
@article{Un1975,
abstract = {In this paper we present a new vocoder called the residual-excited linear prediction (RELP) vocoder. The concept of the RELP vocoder combines the advantages of linear predictive coding (LPC) and voice-excited vocoding. In the RELP system, vocal tract modeling is done by the LPC technique, and the LPC residual signal is used as the excitation signal. After low-pass filtering the residual signal is coded by adaptive delta modulation and is spectrally flattened before being fed in the LPC synthesizer. The range of the transmission rate is typically between 6 and 9.6 kbits/s; the synthetic speech in this range is quite good. As the transmission rate is lowered, the synthetic speech quality degrades very gradually. Since no pitch extraction is required, the vocoder is robust in any operating environment.},
author = {Un, Chong Un Chong and Magill, D.},
doi = {10.1109/TCOM.1975.1092759},
issn = {0090-6778},
journal = {Communications, IEEE Transactions on},
number = {12},
pages = {1466--1474},
title = {{The Residual-Excited Linear Prediction Vocoder with Transmission Rate Below 9.6 kbits/s}},
volume = {23},
year = {1975}
}
@article{Debbal2007,
abstract = {This paper present the analysis and comparisons of the spectrogram, Wigner distribution and wavelet transform techniques to the phonocardiogram signal (PCG). An analysis on the first (S1) and the second cardiac sounds (S2) of the normal phonocardiogram signal is considered here to be able to distinguish the various techniques in their aptitude to separate and present suitably the internal components of these sounds (S1 and S2). A comparison between these methods has shown the resolution differences between them. It is found that the spectrogram short-time Fourier transform (STFT), cannot perfectly detect the two internals components of the first sound (M1 and T1: mitral and tricuspid component respectively) and also the two internals components of the second sound S2 (A2 and P2: atrial and pulmonary component respectively). The Wigner distribution (WD) can provide time-frequency characteristics of the sounds S1 and S2, but with insufficient diagnostic information: the two components, M1 and T1 for the sound S1 and the components A2 and P2 for the sound S2 and P2 are not accurately detected and seem to be one component only. It is found that the wavelet transform (WT) is capable of detecting the two internals components for each sound S1 and S2. However, the standard Fourier transform can display these internals components in frequency but not the time delay between them. Furthermore, the wavelet transform provides more features and characteristics of the sounds that will hemp physicians to obtain qualitative and quantitative measurements of the time-frequency characteristics. ?? 2006 Elsevier Inc. All rights reserved.},
author = {Debbal, S. M. and Bereksi-Reguig, F.},
doi = {10.1016/j.amc.2006.07.005},
issn = {00963003},
journal = {Applied Mathematics and Computation},
keywords = {Comparison,Component A2,Component M1,Component P2,Component T1,FFT,First sound S1,Phonocardiogram signal,STFT,Second sound S2,Technique,Wavelet,Wigner},
number = {2},
pages = {1041--1052},
title = {{Time-frequency analysis of the first and the second heartbeat sounds}},
volume = {184},
year = {2007}
}
@article{Harma2001,
abstract = {Frequency-warped signal processing techniques are attractive to many wideband speech and audio applications since they have a clear connection to the frequency resolution of human hearing. A warped version of linear predictive coding (LPC) is studied. The performance of conventional and warped LPC algorithms are compared in a simulated coding system using listening tests and conventional technical measures. The results indicate that the use of warped techniques is beneficial especially in wideband coding and may result in savings of one bit per sample compared to the conventional algorithm while retaining the same subjective quality},
author = {H\"{a}rm\"{a}, Aki and Laine, Unto K.},
doi = {10.1109/89.928922},
issn = {10636676},
journal = {Speech and Audio Processing, IEEE Transactions on},
keywords = {Audio coding,Frequency-warping,Listening test,Speech coding,Warped linear prediction},
number = {5},
pages = {579--588},
title = {{A comparison of warped and conventional linear predictive coding}},
volume = {9},
year = {2001}
}
@article{Sunwoo1991,
abstract = {A description is given of a real-time implementation of the vector sum-excited linear predictive (VSELP) speech coder, which has been chosen as the digital cellular standard in North America and Japan. This real-time implementation of the VSELP algorithm is realized using a 16-bit general-purpose digital signal processor (GPDSP) with an onchip codec. The principles of the VSELP algorithm and the real-time implementation of the algorithm on the GPDSP chip are addressed. Also discussed are the finite word length effects and possible methods to reduce the effects},
author = {Sunwoo, Myung H. and Park, Sangil},
doi = {10.1109/30.106939},
issn = {00983063},
journal = {Consumer Electronics, IEEE Transactions on},
number = {4},
pages = {772--782},
title = {{Real-time implementation of the VSELP on a 16-bit DSP chip}},
volume = {37},
year = {1991}
}
